{"version":3,"file":"index-ZFYMtjhW.js","sources":["../../../node_modules/diff/lib/index.mjs"],"sourcesContent":["function Diff() {}\nDiff.prototype = {\n  diff: function diff(oldString, newString) {\n    var _options$timeout;\n    var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var callback = options.callback;\n    if (typeof options === 'function') {\n      callback = options;\n      options = {};\n    }\n    var self = this;\n    function done(value) {\n      value = self.postProcess(value, options);\n      if (callback) {\n        setTimeout(function () {\n          callback(value);\n        }, 0);\n        return true;\n      } else {\n        return value;\n      }\n    }\n\n    // Allow subclasses to massage the input prior to running\n    oldString = this.castInput(oldString, options);\n    newString = this.castInput(newString, options);\n    oldString = this.removeEmpty(this.tokenize(oldString, options));\n    newString = this.removeEmpty(this.tokenize(newString, options));\n    var newLen = newString.length,\n      oldLen = oldString.length;\n    var editLength = 1;\n    var maxEditLength = newLen + oldLen;\n    if (options.maxEditLength != null) {\n      maxEditLength = Math.min(maxEditLength, options.maxEditLength);\n    }\n    var maxExecutionTime = (_options$timeout = options.timeout) !== null && _options$timeout !== void 0 ? _options$timeout : Infinity;\n    var abortAfterTimestamp = Date.now() + maxExecutionTime;\n    var bestPath = [{\n      oldPos: -1,\n      lastComponent: undefined\n    }];\n\n    // Seed editLength = 0, i.e. the content starts with the same values\n    var newPos = this.extractCommon(bestPath[0], newString, oldString, 0, options);\n    if (bestPath[0].oldPos + 1 >= oldLen && newPos + 1 >= newLen) {\n      // Identity per the equality and tokenizer\n      return done(buildValues(self, bestPath[0].lastComponent, newString, oldString, self.useLongestToken));\n    }\n\n    // Once we hit the right edge of the edit graph on some diagonal k, we can\n    // definitely reach the end of the edit graph in no more than k edits, so\n    // there's no point in considering any moves to diagonal k+1 any more (from\n    // which we're guaranteed to need at least k+1 more edits).\n    // Similarly, once we've reached the bottom of the edit graph, there's no\n    // point considering moves to lower diagonals.\n    // We record this fact by setting minDiagonalToConsider and\n    // maxDiagonalToConsider to some finite value once we've hit the edge of\n    // the edit graph.\n    // This optimization is not faithful to the original algorithm presented in\n    // Myers's paper, which instead pointlessly extends D-paths off the end of\n    // the edit graph - see page 7 of Myers's paper which notes this point\n    // explicitly and illustrates it with a diagram. This has major performance\n    // implications for some common scenarios. For instance, to compute a diff\n    // where the new text simply appends d characters on the end of the\n    // original text of length n, the true Myers algorithm will take O(n+d^2)\n    // time while this optimization needs only O(n+d) time.\n    var minDiagonalToConsider = -Infinity,\n      maxDiagonalToConsider = Infinity;\n\n    // Main worker method. checks all permutations of a given edit length for acceptance.\n    function execEditLength() {\n      for (var diagonalPath = Math.max(minDiagonalToConsider, -editLength); diagonalPath <= Math.min(maxDiagonalToConsider, editLength); diagonalPath += 2) {\n        var basePath = void 0;\n        var removePath = bestPath[diagonalPath - 1],\n          addPath = bestPath[diagonalPath + 1];\n        if (removePath) {\n          // No one else is going to attempt to use this value, clear it\n          bestPath[diagonalPath - 1] = undefined;\n        }\n        var canAdd = false;\n        if (addPath) {\n          // what newPos will be after we do an insertion:\n          var addPathNewPos = addPath.oldPos - diagonalPath;\n          canAdd = addPath && 0 <= addPathNewPos && addPathNewPos < newLen;\n        }\n        var canRemove = removePath && removePath.oldPos + 1 < oldLen;\n        if (!canAdd && !canRemove) {\n          // If this path is a terminal then prune\n          bestPath[diagonalPath] = undefined;\n          continue;\n        }\n\n        // Select the diagonal that we want to branch from. We select the prior\n        // path whose position in the old string is the farthest from the origin\n        // and does not pass the bounds of the diff graph\n        if (!canRemove || canAdd && removePath.oldPos < addPath.oldPos) {\n          basePath = self.addToPath(addPath, true, false, 0, options);\n        } else {\n          basePath = self.addToPath(removePath, false, true, 1, options);\n        }\n        newPos = self.extractCommon(basePath, newString, oldString, diagonalPath, options);\n        if (basePath.oldPos + 1 >= oldLen && newPos + 1 >= newLen) {\n          // If we have hit the end of both strings, then we are done\n          return done(buildValues(self, basePath.lastComponent, newString, oldString, self.useLongestToken));\n        } else {\n          bestPath[diagonalPath] = basePath;\n          if (basePath.oldPos + 1 >= oldLen) {\n            maxDiagonalToConsider = Math.min(maxDiagonalToConsider, diagonalPath - 1);\n          }\n          if (newPos + 1 >= newLen) {\n            minDiagonalToConsider = Math.max(minDiagonalToConsider, diagonalPath + 1);\n          }\n        }\n      }\n      editLength++;\n    }\n\n    // Performs the length of edit iteration. Is a bit fugly as this has to support the\n    // sync and async mode which is never fun. Loops over execEditLength until a value\n    // is produced, or until the edit length exceeds options.maxEditLength (if given),\n    // in which case it will return undefined.\n    if (callback) {\n      (function exec() {\n        setTimeout(function () {\n          if (editLength > maxEditLength || Date.now() > abortAfterTimestamp) {\n            return callback();\n          }\n          if (!execEditLength()) {\n            exec();\n          }\n        }, 0);\n      })();\n    } else {\n      while (editLength <= maxEditLength && Date.now() <= abortAfterTimestamp) {\n        var ret = execEditLength();\n        if (ret) {\n          return ret;\n        }\n      }\n    }\n  },\n  addToPath: function addToPath(path, added, removed, oldPosInc, options) {\n    var last = path.lastComponent;\n    if (last && !options.oneChangePerToken && last.added === added && last.removed === removed) {\n      return {\n        oldPos: path.oldPos + oldPosInc,\n        lastComponent: {\n          count: last.count + 1,\n          added: added,\n          removed: removed,\n          previousComponent: last.previousComponent\n        }\n      };\n    } else {\n      return {\n        oldPos: path.oldPos + oldPosInc,\n        lastComponent: {\n          count: 1,\n          added: added,\n          removed: removed,\n          previousComponent: last\n        }\n      };\n    }\n  },\n  extractCommon: function extractCommon(basePath, newString, oldString, diagonalPath, options) {\n    var newLen = newString.length,\n      oldLen = oldString.length,\n      oldPos = basePath.oldPos,\n      newPos = oldPos - diagonalPath,\n      commonCount = 0;\n    while (newPos + 1 < newLen && oldPos + 1 < oldLen && this.equals(oldString[oldPos + 1], newString[newPos + 1], options)) {\n      newPos++;\n      oldPos++;\n      commonCount++;\n      if (options.oneChangePerToken) {\n        basePath.lastComponent = {\n          count: 1,\n          previousComponent: basePath.lastComponent,\n          added: false,\n          removed: false\n        };\n      }\n    }\n    if (commonCount && !options.oneChangePerToken) {\n      basePath.lastComponent = {\n        count: commonCount,\n        previousComponent: basePath.lastComponent,\n        added: false,\n        removed: false\n      };\n    }\n    basePath.oldPos = oldPos;\n    return newPos;\n  },\n  equals: function equals(left, right, options) {\n    if (options.comparator) {\n      return options.comparator(left, right);\n    } else {\n      return left === right || options.ignoreCase && left.toLowerCase() === right.toLowerCase();\n    }\n  },\n  removeEmpty: function removeEmpty(array) {\n    var ret = [];\n    for (var i = 0; i < array.length; i++) {\n      if (array[i]) {\n        ret.push(array[i]);\n      }\n    }\n    return ret;\n  },\n  castInput: function castInput(value) {\n    return value;\n  },\n  tokenize: function tokenize(value) {\n    return Array.from(value);\n  },\n  join: function join(chars) {\n    return chars.join('');\n  },\n  postProcess: function postProcess(changeObjects) {\n    return changeObjects;\n  }\n};\nfunction buildValues(diff, lastComponent, newString, oldString, useLongestToken) {\n  // First we convert our linked list of components in reverse order to an\n  // array in the right order:\n  var components = [];\n  var nextComponent;\n  while (lastComponent) {\n    components.push(lastComponent);\n    nextComponent = lastComponent.previousComponent;\n    delete lastComponent.previousComponent;\n    lastComponent = nextComponent;\n  }\n  components.reverse();\n  var componentPos = 0,\n    componentLen = components.length,\n    newPos = 0,\n    oldPos = 0;\n  for (; componentPos < componentLen; componentPos++) {\n    var component = components[componentPos];\n    if (!component.removed) {\n      if (!component.added && useLongestToken) {\n        var value = newString.slice(newPos, newPos + component.count);\n        value = value.map(function (value, i) {\n          var oldValue = oldString[oldPos + i];\n          return oldValue.length > value.length ? oldValue : value;\n        });\n        component.value = diff.join(value);\n      } else {\n        component.value = diff.join(newString.slice(newPos, newPos + component.count));\n      }\n      newPos += component.count;\n\n      // Common case\n      if (!component.added) {\n        oldPos += component.count;\n      }\n    } else {\n      component.value = diff.join(oldString.slice(oldPos, oldPos + component.count));\n      oldPos += component.count;\n    }\n  }\n  return components;\n}\n\nvar characterDiff = new Diff();\nfunction diffChars(oldStr, newStr, options) {\n  return characterDiff.diff(oldStr, newStr, options);\n}\n\nfunction longestCommonPrefix(str1, str2) {\n  var i;\n  for (i = 0; i < str1.length && i < str2.length; i++) {\n    if (str1[i] != str2[i]) {\n      return str1.slice(0, i);\n    }\n  }\n  return str1.slice(0, i);\n}\nfunction longestCommonSuffix(str1, str2) {\n  var i;\n\n  // Unlike longestCommonPrefix, we need a special case to handle all scenarios\n  // where we return the empty string since str1.slice(-0) will return the\n  // entire string.\n  if (!str1 || !str2 || str1[str1.length - 1] != str2[str2.length - 1]) {\n    return '';\n  }\n  for (i = 0; i < str1.length && i < str2.length; i++) {\n    if (str1[str1.length - (i + 1)] != str2[str2.length - (i + 1)]) {\n      return str1.slice(-i);\n    }\n  }\n  return str1.slice(-i);\n}\nfunction replacePrefix(string, oldPrefix, newPrefix) {\n  if (string.slice(0, oldPrefix.length) != oldPrefix) {\n    throw Error(\"string \".concat(JSON.stringify(string), \" doesn't start with prefix \").concat(JSON.stringify(oldPrefix), \"; this is a bug\"));\n  }\n  return newPrefix + string.slice(oldPrefix.length);\n}\nfunction replaceSuffix(string, oldSuffix, newSuffix) {\n  if (!oldSuffix) {\n    return string + newSuffix;\n  }\n  if (string.slice(-oldSuffix.length) != oldSuffix) {\n    throw Error(\"string \".concat(JSON.stringify(string), \" doesn't end with suffix \").concat(JSON.stringify(oldSuffix), \"; this is a bug\"));\n  }\n  return string.slice(0, -oldSuffix.length) + newSuffix;\n}\nfunction removePrefix(string, oldPrefix) {\n  return replacePrefix(string, oldPrefix, '');\n}\nfunction removeSuffix(string, oldSuffix) {\n  return replaceSuffix(string, oldSuffix, '');\n}\nfunction maximumOverlap(string1, string2) {\n  return string2.slice(0, overlapCount(string1, string2));\n}\n\n// Nicked from https://stackoverflow.com/a/60422853/1709587\nfunction overlapCount(a, b) {\n  // Deal with cases where the strings differ in length\n  var startA = 0;\n  if (a.length > b.length) {\n    startA = a.length - b.length;\n  }\n  var endB = b.length;\n  if (a.length < b.length) {\n    endB = a.length;\n  }\n  // Create a back-reference for each index\n  //   that should be followed in case of a mismatch.\n  //   We only need B to make these references:\n  var map = Array(endB);\n  var k = 0; // Index that lags behind j\n  map[0] = 0;\n  for (var j = 1; j < endB; j++) {\n    if (b[j] == b[k]) {\n      map[j] = map[k]; // skip over the same character (optional optimisation)\n    } else {\n      map[j] = k;\n    }\n    while (k > 0 && b[j] != b[k]) {\n      k = map[k];\n    }\n    if (b[j] == b[k]) {\n      k++;\n    }\n  }\n  // Phase 2: use these references while iterating over A\n  k = 0;\n  for (var i = startA; i < a.length; i++) {\n    while (k > 0 && a[i] != b[k]) {\n      k = map[k];\n    }\n    if (a[i] == b[k]) {\n      k++;\n    }\n  }\n  return k;\n}\n\n/**\n * Returns true if the string consistently uses Windows line endings.\n */\nfunction hasOnlyWinLineEndings(string) {\n  return string.includes('\\r\\n') && !string.startsWith('\\n') && !string.match(/[^\\r]\\n/);\n}\n\n/**\n * Returns true if the string consistently uses Unix line endings.\n */\nfunction hasOnlyUnixLineEndings(string) {\n  return !string.includes('\\r\\n') && string.includes('\\n');\n}\n\n// Based on https://en.wikipedia.org/wiki/Latin_script_in_Unicode\n//\n// Ranges and exceptions:\n// Latin-1 Supplement, 0080–00FF\n//  - U+00D7  × Multiplication sign\n//  - U+00F7  ÷ Division sign\n// Latin Extended-A, 0100–017F\n// Latin Extended-B, 0180–024F\n// IPA Extensions, 0250–02AF\n// Spacing Modifier Letters, 02B0–02FF\n//  - U+02C7  ˇ &#711;  Caron\n//  - U+02D8  ˘ &#728;  Breve\n//  - U+02D9  ˙ &#729;  Dot Above\n//  - U+02DA  ˚ &#730;  Ring Above\n//  - U+02DB  ˛ &#731;  Ogonek\n//  - U+02DC  ˜ &#732;  Small Tilde\n//  - U+02DD  ˝ &#733;  Double Acute Accent\n// Latin Extended Additional, 1E00–1EFF\nvar extendedWordChars = \"a-zA-Z0-9_\\\\u{C0}-\\\\u{FF}\\\\u{D8}-\\\\u{F6}\\\\u{F8}-\\\\u{2C6}\\\\u{2C8}-\\\\u{2D7}\\\\u{2DE}-\\\\u{2FF}\\\\u{1E00}-\\\\u{1EFF}\";\n\n// Each token is one of the following:\n// - A punctuation mark plus the surrounding whitespace\n// - A word plus the surrounding whitespace\n// - Pure whitespace (but only in the special case where this the entire text\n//   is just whitespace)\n//\n// We have to include surrounding whitespace in the tokens because the two\n// alternative approaches produce horribly broken results:\n// * If we just discard the whitespace, we can't fully reproduce the original\n//   text from the sequence of tokens and any attempt to render the diff will\n//   get the whitespace wrong.\n// * If we have separate tokens for whitespace, then in a typical text every\n//   second token will be a single space character. But this often results in\n//   the optimal diff between two texts being a perverse one that preserves\n//   the spaces between words but deletes and reinserts actual common words.\n//   See https://github.com/kpdecker/jsdiff/issues/160#issuecomment-1866099640\n//   for an example.\n//\n// Keeping the surrounding whitespace of course has implications for .equals\n// and .join, not just .tokenize.\n\n// This regex does NOT fully implement the tokenization rules described above.\n// Instead, it gives runs of whitespace their own \"token\". The tokenize method\n// then handles stitching whitespace tokens onto adjacent word or punctuation\n// tokens.\nvar tokenizeIncludingWhitespace = new RegExp(\"[\".concat(extendedWordChars, \"]+|\\\\s+|[^\").concat(extendedWordChars, \"]\"), 'ug');\nvar wordDiff = new Diff();\nwordDiff.equals = function (left, right, options) {\n  if (options.ignoreCase) {\n    left = left.toLowerCase();\n    right = right.toLowerCase();\n  }\n  return left.trim() === right.trim();\n};\nwordDiff.tokenize = function (value) {\n  var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var parts;\n  if (options.intlSegmenter) {\n    if (options.intlSegmenter.resolvedOptions().granularity != 'word') {\n      throw new Error('The segmenter passed must have a granularity of \"word\"');\n    }\n    parts = Array.from(options.intlSegmenter.segment(value), function (segment) {\n      return segment.segment;\n    });\n  } else {\n    parts = value.match(tokenizeIncludingWhitespace) || [];\n  }\n  var tokens = [];\n  var prevPart = null;\n  parts.forEach(function (part) {\n    if (/\\s/.test(part)) {\n      if (prevPart == null) {\n        tokens.push(part);\n      } else {\n        tokens.push(tokens.pop() + part);\n      }\n    } else if (/\\s/.test(prevPart)) {\n      if (tokens[tokens.length - 1] == prevPart) {\n        tokens.push(tokens.pop() + part);\n      } else {\n        tokens.push(prevPart + part);\n      }\n    } else {\n      tokens.push(part);\n    }\n    prevPart = part;\n  });\n  return tokens;\n};\nwordDiff.join = function (tokens) {\n  // Tokens being joined here will always have appeared consecutively in the\n  // same text, so we can simply strip off the leading whitespace from all the\n  // tokens except the first (and except any whitespace-only tokens - but such\n  // a token will always be the first and only token anyway) and then join them\n  // and the whitespace around words and punctuation will end up correct.\n  return tokens.map(function (token, i) {\n    if (i == 0) {\n      return token;\n    } else {\n      return token.replace(/^\\s+/, '');\n    }\n  }).join('');\n};\nwordDiff.postProcess = function (changes, options) {\n  if (!changes || options.oneChangePerToken) {\n    return changes;\n  }\n  var lastKeep = null;\n  // Change objects representing any insertion or deletion since the last\n  // \"keep\" change object. There can be at most one of each.\n  var insertion = null;\n  var deletion = null;\n  changes.forEach(function (change) {\n    if (change.added) {\n      insertion = change;\n    } else if (change.removed) {\n      deletion = change;\n    } else {\n      if (insertion || deletion) {\n        // May be false at start of text\n        dedupeWhitespaceInChangeObjects(lastKeep, deletion, insertion, change);\n      }\n      lastKeep = change;\n      insertion = null;\n      deletion = null;\n    }\n  });\n  if (insertion || deletion) {\n    dedupeWhitespaceInChangeObjects(lastKeep, deletion, insertion, null);\n  }\n  return changes;\n};\nfunction diffWords(oldStr, newStr, options) {\n  // This option has never been documented and never will be (it's clearer to\n  // just call `diffWordsWithSpace` directly if you need that behavior), but\n  // has existed in jsdiff for a long time, so we retain support for it here\n  // for the sake of backwards compatibility.\n  if ((options === null || options === void 0 ? void 0 : options.ignoreWhitespace) != null && !options.ignoreWhitespace) {\n    return diffWordsWithSpace(oldStr, newStr, options);\n  }\n  return wordDiff.diff(oldStr, newStr, options);\n}\nfunction dedupeWhitespaceInChangeObjects(startKeep, deletion, insertion, endKeep) {\n  // Before returning, we tidy up the leading and trailing whitespace of the\n  // change objects to eliminate cases where trailing whitespace in one object\n  // is repeated as leading whitespace in the next.\n  // Below are examples of the outcomes we want here to explain the code.\n  // I=insert, K=keep, D=delete\n  // 1. diffing 'foo bar baz' vs 'foo baz'\n  //    Prior to cleanup, we have K:'foo ' D:' bar ' K:' baz'\n  //    After cleanup, we want:   K:'foo ' D:'bar ' K:'baz'\n  //\n  // 2. Diffing 'foo bar baz' vs 'foo qux baz'\n  //    Prior to cleanup, we have K:'foo ' D:' bar ' I:' qux ' K:' baz'\n  //    After cleanup, we want K:'foo ' D:'bar' I:'qux' K:' baz'\n  //\n  // 3. Diffing 'foo\\nbar baz' vs 'foo baz'\n  //    Prior to cleanup, we have K:'foo ' D:'\\nbar ' K:' baz'\n  //    After cleanup, we want K'foo' D:'\\nbar' K:' baz'\n  //\n  // 4. Diffing 'foo baz' vs 'foo\\nbar baz'\n  //    Prior to cleanup, we have K:'foo\\n' I:'\\nbar ' K:' baz'\n  //    After cleanup, we ideally want K'foo' I:'\\nbar' K:' baz'\n  //    but don't actually manage this currently (the pre-cleanup change\n  //    objects don't contain enough information to make it possible).\n  //\n  // 5. Diffing 'foo   bar baz' vs 'foo  baz'\n  //    Prior to cleanup, we have K:'foo  ' D:'   bar ' K:'  baz'\n  //    After cleanup, we want K:'foo  ' D:' bar ' K:'baz'\n  //\n  // Our handling is unavoidably imperfect in the case where there's a single\n  // indel between keeps and the whitespace has changed. For instance, consider\n  // diffing 'foo\\tbar\\nbaz' vs 'foo baz'. Unless we create an extra change\n  // object to represent the insertion of the space character (which isn't even\n  // a token), we have no way to avoid losing information about the texts'\n  // original whitespace in the result we return. Still, we do our best to\n  // output something that will look sensible if we e.g. print it with\n  // insertions in green and deletions in red.\n\n  // Between two \"keep\" change objects (or before the first or after the last\n  // change object), we can have either:\n  // * A \"delete\" followed by an \"insert\"\n  // * Just an \"insert\"\n  // * Just a \"delete\"\n  // We handle the three cases separately.\n  if (deletion && insertion) {\n    var oldWsPrefix = deletion.value.match(/^\\s*/)[0];\n    var oldWsSuffix = deletion.value.match(/\\s*$/)[0];\n    var newWsPrefix = insertion.value.match(/^\\s*/)[0];\n    var newWsSuffix = insertion.value.match(/\\s*$/)[0];\n    if (startKeep) {\n      var commonWsPrefix = longestCommonPrefix(oldWsPrefix, newWsPrefix);\n      startKeep.value = replaceSuffix(startKeep.value, newWsPrefix, commonWsPrefix);\n      deletion.value = removePrefix(deletion.value, commonWsPrefix);\n      insertion.value = removePrefix(insertion.value, commonWsPrefix);\n    }\n    if (endKeep) {\n      var commonWsSuffix = longestCommonSuffix(oldWsSuffix, newWsSuffix);\n      endKeep.value = replacePrefix(endKeep.value, newWsSuffix, commonWsSuffix);\n      deletion.value = removeSuffix(deletion.value, commonWsSuffix);\n      insertion.value = removeSuffix(insertion.value, commonWsSuffix);\n    }\n  } else if (insertion) {\n    // The whitespaces all reflect what was in the new text rather than\n    // the old, so we essentially have no information about whitespace\n    // insertion or deletion. We just want to dedupe the whitespace.\n    // We do that by having each change object keep its trailing\n    // whitespace and deleting duplicate leading whitespace where\n    // present.\n    if (startKeep) {\n      insertion.value = insertion.value.replace(/^\\s*/, '');\n    }\n    if (endKeep) {\n      endKeep.value = endKeep.value.replace(/^\\s*/, '');\n    }\n    // otherwise we've got a deletion and no insertion\n  } else if (startKeep && endKeep) {\n    var newWsFull = endKeep.value.match(/^\\s*/)[0],\n      delWsStart = deletion.value.match(/^\\s*/)[0],\n      delWsEnd = deletion.value.match(/\\s*$/)[0];\n\n    // Any whitespace that comes straight after startKeep in both the old and\n    // new texts, assign to startKeep and remove from the deletion.\n    var newWsStart = longestCommonPrefix(newWsFull, delWsStart);\n    deletion.value = removePrefix(deletion.value, newWsStart);\n\n    // Any whitespace that comes straight before endKeep in both the old and\n    // new texts, and hasn't already been assigned to startKeep, assign to\n    // endKeep and remove from the deletion.\n    var newWsEnd = longestCommonSuffix(removePrefix(newWsFull, newWsStart), delWsEnd);\n    deletion.value = removeSuffix(deletion.value, newWsEnd);\n    endKeep.value = replacePrefix(endKeep.value, newWsFull, newWsEnd);\n\n    // If there's any whitespace from the new text that HASN'T already been\n    // assigned, assign it to the start:\n    startKeep.value = replaceSuffix(startKeep.value, newWsFull, newWsFull.slice(0, newWsFull.length - newWsEnd.length));\n  } else if (endKeep) {\n    // We are at the start of the text. Preserve all the whitespace on\n    // endKeep, and just remove whitespace from the end of deletion to the\n    // extent that it overlaps with the start of endKeep.\n    var endKeepWsPrefix = endKeep.value.match(/^\\s*/)[0];\n    var deletionWsSuffix = deletion.value.match(/\\s*$/)[0];\n    var overlap = maximumOverlap(deletionWsSuffix, endKeepWsPrefix);\n    deletion.value = removeSuffix(deletion.value, overlap);\n  } else if (startKeep) {\n    // We are at the END of the text. Preserve all the whitespace on\n    // startKeep, and just remove whitespace from the start of deletion to\n    // the extent that it overlaps with the end of startKeep.\n    var startKeepWsSuffix = startKeep.value.match(/\\s*$/)[0];\n    var deletionWsPrefix = deletion.value.match(/^\\s*/)[0];\n    var _overlap = maximumOverlap(startKeepWsSuffix, deletionWsPrefix);\n    deletion.value = removePrefix(deletion.value, _overlap);\n  }\n}\nvar wordWithSpaceDiff = new Diff();\nwordWithSpaceDiff.tokenize = function (value) {\n  // Slightly different to the tokenizeIncludingWhitespace regex used above in\n  // that this one treats each individual newline as a distinct tokens, rather\n  // than merging them into other surrounding whitespace. This was requested\n  // in https://github.com/kpdecker/jsdiff/issues/180 &\n  //    https://github.com/kpdecker/jsdiff/issues/211\n  var regex = new RegExp(\"(\\\\r?\\\\n)|[\".concat(extendedWordChars, \"]+|[^\\\\S\\\\n\\\\r]+|[^\").concat(extendedWordChars, \"]\"), 'ug');\n  return value.match(regex) || [];\n};\nfunction diffWordsWithSpace(oldStr, newStr, options) {\n  return wordWithSpaceDiff.diff(oldStr, newStr, options);\n}\n\nfunction generateOptions(options, defaults) {\n  if (typeof options === 'function') {\n    defaults.callback = options;\n  } else if (options) {\n    for (var name in options) {\n      /* istanbul ignore else */\n      if (options.hasOwnProperty(name)) {\n        defaults[name] = options[name];\n      }\n    }\n  }\n  return defaults;\n}\n\nvar lineDiff = new Diff();\nlineDiff.tokenize = function (value, options) {\n  if (options.stripTrailingCr) {\n    // remove one \\r before \\n to match GNU diff's --strip-trailing-cr behavior\n    value = value.replace(/\\r\\n/g, '\\n');\n  }\n  var retLines = [],\n    linesAndNewlines = value.split(/(\\n|\\r\\n)/);\n\n  // Ignore the final empty token that occurs if the string ends with a new line\n  if (!linesAndNewlines[linesAndNewlines.length - 1]) {\n    linesAndNewlines.pop();\n  }\n\n  // Merge the content and line separators into single tokens\n  for (var i = 0; i < linesAndNewlines.length; i++) {\n    var line = linesAndNewlines[i];\n    if (i % 2 && !options.newlineIsToken) {\n      retLines[retLines.length - 1] += line;\n    } else {\n      retLines.push(line);\n    }\n  }\n  return retLines;\n};\nlineDiff.equals = function (left, right, options) {\n  // If we're ignoring whitespace, we need to normalise lines by stripping\n  // whitespace before checking equality. (This has an annoying interaction\n  // with newlineIsToken that requires special handling: if newlines get their\n  // own token, then we DON'T want to trim the *newline* tokens down to empty\n  // strings, since this would cause us to treat whitespace-only line content\n  // as equal to a separator between lines, which would be weird and\n  // inconsistent with the documented behavior of the options.)\n  if (options.ignoreWhitespace) {\n    if (!options.newlineIsToken || !left.includes('\\n')) {\n      left = left.trim();\n    }\n    if (!options.newlineIsToken || !right.includes('\\n')) {\n      right = right.trim();\n    }\n  } else if (options.ignoreNewlineAtEof && !options.newlineIsToken) {\n    if (left.endsWith('\\n')) {\n      left = left.slice(0, -1);\n    }\n    if (right.endsWith('\\n')) {\n      right = right.slice(0, -1);\n    }\n  }\n  return Diff.prototype.equals.call(this, left, right, options);\n};\nfunction diffLines(oldStr, newStr, callback) {\n  return lineDiff.diff(oldStr, newStr, callback);\n}\n\n// Kept for backwards compatibility. This is a rather arbitrary wrapper method\n// that just calls `diffLines` with `ignoreWhitespace: true`. It's confusing to\n// have two ways to do exactly the same thing in the API, so we no longer\n// document this one (library users should explicitly use `diffLines` with\n// `ignoreWhitespace: true` instead) but we keep it around to maintain\n// compatibility with code that used old versions.\nfunction diffTrimmedLines(oldStr, newStr, callback) {\n  var options = generateOptions(callback, {\n    ignoreWhitespace: true\n  });\n  return lineDiff.diff(oldStr, newStr, options);\n}\n\nvar sentenceDiff = new Diff();\nsentenceDiff.tokenize = function (value) {\n  return value.split(/(\\S.+?[.!?])(?=\\s+|$)/);\n};\nfunction diffSentences(oldStr, newStr, callback) {\n  return sentenceDiff.diff(oldStr, newStr, callback);\n}\n\nvar cssDiff = new Diff();\ncssDiff.tokenize = function (value) {\n  return value.split(/([{}:;,]|\\s+)/);\n};\nfunction diffCss(oldStr, newStr, callback) {\n  return cssDiff.diff(oldStr, newStr, callback);\n}\n\nfunction ownKeys(e, r) {\n  var t = Object.keys(e);\n  if (Object.getOwnPropertySymbols) {\n    var o = Object.getOwnPropertySymbols(e);\n    r && (o = o.filter(function (r) {\n      return Object.getOwnPropertyDescriptor(e, r).enumerable;\n    })), t.push.apply(t, o);\n  }\n  return t;\n}\nfunction _objectSpread2(e) {\n  for (var r = 1; r < arguments.length; r++) {\n    var t = null != arguments[r] ? arguments[r] : {};\n    r % 2 ? ownKeys(Object(t), !0).forEach(function (r) {\n      _defineProperty(e, r, t[r]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) {\n      Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r));\n    });\n  }\n  return e;\n}\nfunction _toPrimitive(t, r) {\n  if (\"object\" != typeof t || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != typeof i) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\nfunction _toPropertyKey(t) {\n  var i = _toPrimitive(t, \"string\");\n  return \"symbol\" == typeof i ? i : i + \"\";\n}\nfunction _typeof(o) {\n  \"@babel/helpers - typeof\";\n\n  return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) {\n    return typeof o;\n  } : function (o) {\n    return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o;\n  }, _typeof(o);\n}\nfunction _defineProperty(obj, key, value) {\n  key = _toPropertyKey(key);\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n  return obj;\n}\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && iter[Symbol.iterator] != null || iter[\"@@iterator\"] != null) return Array.from(iter);\n}\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n  for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i];\n  return arr2;\n}\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nvar jsonDiff = new Diff();\n// Discriminate between two lines of pretty-printed, serialized JSON where one of them has a\n// dangling comma and the other doesn't. Turns out including the dangling comma yields the nicest output:\njsonDiff.useLongestToken = true;\njsonDiff.tokenize = lineDiff.tokenize;\njsonDiff.castInput = function (value, options) {\n  var undefinedReplacement = options.undefinedReplacement,\n    _options$stringifyRep = options.stringifyReplacer,\n    stringifyReplacer = _options$stringifyRep === void 0 ? function (k, v) {\n      return typeof v === 'undefined' ? undefinedReplacement : v;\n    } : _options$stringifyRep;\n  return typeof value === 'string' ? value : JSON.stringify(canonicalize(value, null, null, stringifyReplacer), stringifyReplacer, '  ');\n};\njsonDiff.equals = function (left, right, options) {\n  return Diff.prototype.equals.call(jsonDiff, left.replace(/,([\\r\\n])/g, '$1'), right.replace(/,([\\r\\n])/g, '$1'), options);\n};\nfunction diffJson(oldObj, newObj, options) {\n  return jsonDiff.diff(oldObj, newObj, options);\n}\n\n// This function handles the presence of circular references by bailing out when encountering an\n// object that is already on the \"stack\" of items being processed. Accepts an optional replacer\nfunction canonicalize(obj, stack, replacementStack, replacer, key) {\n  stack = stack || [];\n  replacementStack = replacementStack || [];\n  if (replacer) {\n    obj = replacer(key, obj);\n  }\n  var i;\n  for (i = 0; i < stack.length; i += 1) {\n    if (stack[i] === obj) {\n      return replacementStack[i];\n    }\n  }\n  var canonicalizedObj;\n  if ('[object Array]' === Object.prototype.toString.call(obj)) {\n    stack.push(obj);\n    canonicalizedObj = new Array(obj.length);\n    replacementStack.push(canonicalizedObj);\n    for (i = 0; i < obj.length; i += 1) {\n      canonicalizedObj[i] = canonicalize(obj[i], stack, replacementStack, replacer, key);\n    }\n    stack.pop();\n    replacementStack.pop();\n    return canonicalizedObj;\n  }\n  if (obj && obj.toJSON) {\n    obj = obj.toJSON();\n  }\n  if (_typeof(obj) === 'object' && obj !== null) {\n    stack.push(obj);\n    canonicalizedObj = {};\n    replacementStack.push(canonicalizedObj);\n    var sortedKeys = [],\n      _key;\n    for (_key in obj) {\n      /* istanbul ignore else */\n      if (Object.prototype.hasOwnProperty.call(obj, _key)) {\n        sortedKeys.push(_key);\n      }\n    }\n    sortedKeys.sort();\n    for (i = 0; i < sortedKeys.length; i += 1) {\n      _key = sortedKeys[i];\n      canonicalizedObj[_key] = canonicalize(obj[_key], stack, replacementStack, replacer, _key);\n    }\n    stack.pop();\n    replacementStack.pop();\n  } else {\n    canonicalizedObj = obj;\n  }\n  return canonicalizedObj;\n}\n\nvar arrayDiff = new Diff();\narrayDiff.tokenize = function (value) {\n  return value.slice();\n};\narrayDiff.join = arrayDiff.removeEmpty = function (value) {\n  return value;\n};\nfunction diffArrays(oldArr, newArr, callback) {\n  return arrayDiff.diff(oldArr, newArr, callback);\n}\n\nfunction unixToWin(patch) {\n  if (Array.isArray(patch)) {\n    return patch.map(unixToWin);\n  }\n  return _objectSpread2(_objectSpread2({}, patch), {}, {\n    hunks: patch.hunks.map(function (hunk) {\n      return _objectSpread2(_objectSpread2({}, hunk), {}, {\n        lines: hunk.lines.map(function (line, i) {\n          var _hunk$lines;\n          return line.startsWith('\\\\') || line.endsWith('\\r') || (_hunk$lines = hunk.lines[i + 1]) !== null && _hunk$lines !== void 0 && _hunk$lines.startsWith('\\\\') ? line : line + '\\r';\n        })\n      });\n    })\n  });\n}\nfunction winToUnix(patch) {\n  if (Array.isArray(patch)) {\n    return patch.map(winToUnix);\n  }\n  return _objectSpread2(_objectSpread2({}, patch), {}, {\n    hunks: patch.hunks.map(function (hunk) {\n      return _objectSpread2(_objectSpread2({}, hunk), {}, {\n        lines: hunk.lines.map(function (line) {\n          return line.endsWith('\\r') ? line.substring(0, line.length - 1) : line;\n        })\n      });\n    })\n  });\n}\n\n/**\n * Returns true if the patch consistently uses Unix line endings (or only involves one line and has\n * no line endings).\n */\nfunction isUnix(patch) {\n  if (!Array.isArray(patch)) {\n    patch = [patch];\n  }\n  return !patch.some(function (index) {\n    return index.hunks.some(function (hunk) {\n      return hunk.lines.some(function (line) {\n        return !line.startsWith('\\\\') && line.endsWith('\\r');\n      });\n    });\n  });\n}\n\n/**\n * Returns true if the patch uses Windows line endings and only Windows line endings.\n */\nfunction isWin(patch) {\n  if (!Array.isArray(patch)) {\n    patch = [patch];\n  }\n  return patch.some(function (index) {\n    return index.hunks.some(function (hunk) {\n      return hunk.lines.some(function (line) {\n        return line.endsWith('\\r');\n      });\n    });\n  }) && patch.every(function (index) {\n    return index.hunks.every(function (hunk) {\n      return hunk.lines.every(function (line, i) {\n        var _hunk$lines2;\n        return line.startsWith('\\\\') || line.endsWith('\\r') || ((_hunk$lines2 = hunk.lines[i + 1]) === null || _hunk$lines2 === void 0 ? void 0 : _hunk$lines2.startsWith('\\\\'));\n      });\n    });\n  });\n}\n\nfunction parsePatch(uniDiff) {\n  var diffstr = uniDiff.split(/\\n/),\n    list = [],\n    i = 0;\n  function parseIndex() {\n    var index = {};\n    list.push(index);\n\n    // Parse diff metadata\n    while (i < diffstr.length) {\n      var line = diffstr[i];\n\n      // File header found, end parsing diff metadata\n      if (/^(\\-\\-\\-|\\+\\+\\+|@@)\\s/.test(line)) {\n        break;\n      }\n\n      // Diff index\n      var header = /^(?:Index:|diff(?: -r \\w+)+)\\s+(.+?)\\s*$/.exec(line);\n      if (header) {\n        index.index = header[1];\n      }\n      i++;\n    }\n\n    // Parse file headers if they are defined. Unified diff requires them, but\n    // there's no technical issues to have an isolated hunk without file header\n    parseFileHeader(index);\n    parseFileHeader(index);\n\n    // Parse hunks\n    index.hunks = [];\n    while (i < diffstr.length) {\n      var _line = diffstr[i];\n      if (/^(Index:\\s|diff\\s|\\-\\-\\-\\s|\\+\\+\\+\\s|===================================================================)/.test(_line)) {\n        break;\n      } else if (/^@@/.test(_line)) {\n        index.hunks.push(parseHunk());\n      } else if (_line) {\n        throw new Error('Unknown line ' + (i + 1) + ' ' + JSON.stringify(_line));\n      } else {\n        i++;\n      }\n    }\n  }\n\n  // Parses the --- and +++ headers, if none are found, no lines\n  // are consumed.\n  function parseFileHeader(index) {\n    var fileHeader = /^(---|\\+\\+\\+)\\s+(.*)\\r?$/.exec(diffstr[i]);\n    if (fileHeader) {\n      var keyPrefix = fileHeader[1] === '---' ? 'old' : 'new';\n      var data = fileHeader[2].split('\\t', 2);\n      var fileName = data[0].replace(/\\\\\\\\/g, '\\\\');\n      if (/^\".*\"$/.test(fileName)) {\n        fileName = fileName.substr(1, fileName.length - 2);\n      }\n      index[keyPrefix + 'FileName'] = fileName;\n      index[keyPrefix + 'Header'] = (data[1] || '').trim();\n      i++;\n    }\n  }\n\n  // Parses a hunk\n  // This assumes that we are at the start of a hunk.\n  function parseHunk() {\n    var chunkHeaderIndex = i,\n      chunkHeaderLine = diffstr[i++],\n      chunkHeader = chunkHeaderLine.split(/@@ -(\\d+)(?:,(\\d+))? \\+(\\d+)(?:,(\\d+))? @@/);\n    var hunk = {\n      oldStart: +chunkHeader[1],\n      oldLines: typeof chunkHeader[2] === 'undefined' ? 1 : +chunkHeader[2],\n      newStart: +chunkHeader[3],\n      newLines: typeof chunkHeader[4] === 'undefined' ? 1 : +chunkHeader[4],\n      lines: []\n    };\n\n    // Unified Diff Format quirk: If the chunk size is 0,\n    // the first number is one lower than one would expect.\n    // https://www.artima.com/weblogs/viewpost.jsp?thread=164293\n    if (hunk.oldLines === 0) {\n      hunk.oldStart += 1;\n    }\n    if (hunk.newLines === 0) {\n      hunk.newStart += 1;\n    }\n    var addCount = 0,\n      removeCount = 0;\n    for (; i < diffstr.length && (removeCount < hunk.oldLines || addCount < hunk.newLines || (_diffstr$i = diffstr[i]) !== null && _diffstr$i !== void 0 && _diffstr$i.startsWith('\\\\')); i++) {\n      var _diffstr$i;\n      var operation = diffstr[i].length == 0 && i != diffstr.length - 1 ? ' ' : diffstr[i][0];\n      if (operation === '+' || operation === '-' || operation === ' ' || operation === '\\\\') {\n        hunk.lines.push(diffstr[i]);\n        if (operation === '+') {\n          addCount++;\n        } else if (operation === '-') {\n          removeCount++;\n        } else if (operation === ' ') {\n          addCount++;\n          removeCount++;\n        }\n      } else {\n        throw new Error(\"Hunk at line \".concat(chunkHeaderIndex + 1, \" contained invalid line \").concat(diffstr[i]));\n      }\n    }\n\n    // Handle the empty block count case\n    if (!addCount && hunk.newLines === 1) {\n      hunk.newLines = 0;\n    }\n    if (!removeCount && hunk.oldLines === 1) {\n      hunk.oldLines = 0;\n    }\n\n    // Perform sanity checking\n    if (addCount !== hunk.newLines) {\n      throw new Error('Added line count did not match for hunk at line ' + (chunkHeaderIndex + 1));\n    }\n    if (removeCount !== hunk.oldLines) {\n      throw new Error('Removed line count did not match for hunk at line ' + (chunkHeaderIndex + 1));\n    }\n    return hunk;\n  }\n  while (i < diffstr.length) {\n    parseIndex();\n  }\n  return list;\n}\n\n// Iterator that traverses in the range of [min, max], stepping\n// by distance from a given start position. I.e. for [0, 4], with\n// start of 2, this will iterate 2, 3, 1, 4, 0.\nfunction distanceIterator (start, minLine, maxLine) {\n  var wantForward = true,\n    backwardExhausted = false,\n    forwardExhausted = false,\n    localOffset = 1;\n  return function iterator() {\n    if (wantForward && !forwardExhausted) {\n      if (backwardExhausted) {\n        localOffset++;\n      } else {\n        wantForward = false;\n      }\n\n      // Check if trying to fit beyond text length, and if not, check it fits\n      // after offset location (or desired location on first iteration)\n      if (start + localOffset <= maxLine) {\n        return start + localOffset;\n      }\n      forwardExhausted = true;\n    }\n    if (!backwardExhausted) {\n      if (!forwardExhausted) {\n        wantForward = true;\n      }\n\n      // Check if trying to fit before text beginning, and if not, check it fits\n      // before offset location\n      if (minLine <= start - localOffset) {\n        return start - localOffset++;\n      }\n      backwardExhausted = true;\n      return iterator();\n    }\n\n    // We tried to fit hunk before text beginning and beyond text length, then\n    // hunk can't fit on the text. Return undefined\n  };\n}\n\nfunction applyPatch(source, uniDiff) {\n  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n  if (Array.isArray(uniDiff)) {\n    if (uniDiff.length > 1) {\n      throw new Error('applyPatch only works with a single input.');\n    }\n    uniDiff = uniDiff[0];\n  }\n  if (options.autoConvertLineEndings || options.autoConvertLineEndings == null) {\n    if (hasOnlyWinLineEndings(source) && isUnix(uniDiff)) {\n      uniDiff = unixToWin(uniDiff);\n    } else if (hasOnlyUnixLineEndings(source) && isWin(uniDiff)) {\n      uniDiff = winToUnix(uniDiff);\n    }\n  }\n\n  // Apply the diff to the input\n  var lines = source.split('\\n'),\n    hunks = uniDiff.hunks,\n    compareLine = options.compareLine || function (lineNumber, line, operation, patchContent) {\n      return line === patchContent;\n    },\n    fuzzFactor = options.fuzzFactor || 0,\n    minLine = 0;\n  if (fuzzFactor < 0 || !Number.isInteger(fuzzFactor)) {\n    throw new Error('fuzzFactor must be a non-negative integer');\n  }\n\n  // Special case for empty patch.\n  if (!hunks.length) {\n    return source;\n  }\n\n  // Before anything else, handle EOFNL insertion/removal. If the patch tells us to make a change\n  // to the EOFNL that is redundant/impossible - i.e. to remove a newline that's not there, or add a\n  // newline that already exists - then we either return false and fail to apply the patch (if\n  // fuzzFactor is 0) or simply ignore the problem and do nothing (if fuzzFactor is >0).\n  // If we do need to remove/add a newline at EOF, this will always be in the final hunk:\n  var prevLine = '',\n    removeEOFNL = false,\n    addEOFNL = false;\n  for (var i = 0; i < hunks[hunks.length - 1].lines.length; i++) {\n    var line = hunks[hunks.length - 1].lines[i];\n    if (line[0] == '\\\\') {\n      if (prevLine[0] == '+') {\n        removeEOFNL = true;\n      } else if (prevLine[0] == '-') {\n        addEOFNL = true;\n      }\n    }\n    prevLine = line;\n  }\n  if (removeEOFNL) {\n    if (addEOFNL) {\n      // This means the final line gets changed but doesn't have a trailing newline in either the\n      // original or patched version. In that case, we do nothing if fuzzFactor > 0, and if\n      // fuzzFactor is 0, we simply validate that the source file has no trailing newline.\n      if (!fuzzFactor && lines[lines.length - 1] == '') {\n        return false;\n      }\n    } else if (lines[lines.length - 1] == '') {\n      lines.pop();\n    } else if (!fuzzFactor) {\n      return false;\n    }\n  } else if (addEOFNL) {\n    if (lines[lines.length - 1] != '') {\n      lines.push('');\n    } else if (!fuzzFactor) {\n      return false;\n    }\n  }\n\n  /**\n   * Checks if the hunk can be made to fit at the provided location with at most `maxErrors`\n   * insertions, substitutions, or deletions, while ensuring also that:\n   * - lines deleted in the hunk match exactly, and\n   * - wherever an insertion operation or block of insertion operations appears in the hunk, the\n   *   immediately preceding and following lines of context match exactly\n   *\n   * `toPos` should be set such that lines[toPos] is meant to match hunkLines[0].\n   *\n   * If the hunk can be applied, returns an object with properties `oldLineLastI` and\n   * `replacementLines`. Otherwise, returns null.\n   */\n  function applyHunk(hunkLines, toPos, maxErrors) {\n    var hunkLinesI = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var lastContextLineMatched = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : true;\n    var patchedLines = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [];\n    var patchedLinesLength = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;\n    var nConsecutiveOldContextLines = 0;\n    var nextContextLineMustMatch = false;\n    for (; hunkLinesI < hunkLines.length; hunkLinesI++) {\n      var hunkLine = hunkLines[hunkLinesI],\n        operation = hunkLine.length > 0 ? hunkLine[0] : ' ',\n        content = hunkLine.length > 0 ? hunkLine.substr(1) : hunkLine;\n      if (operation === '-') {\n        if (compareLine(toPos + 1, lines[toPos], operation, content)) {\n          toPos++;\n          nConsecutiveOldContextLines = 0;\n        } else {\n          if (!maxErrors || lines[toPos] == null) {\n            return null;\n          }\n          patchedLines[patchedLinesLength] = lines[toPos];\n          return applyHunk(hunkLines, toPos + 1, maxErrors - 1, hunkLinesI, false, patchedLines, patchedLinesLength + 1);\n        }\n      }\n      if (operation === '+') {\n        if (!lastContextLineMatched) {\n          return null;\n        }\n        patchedLines[patchedLinesLength] = content;\n        patchedLinesLength++;\n        nConsecutiveOldContextLines = 0;\n        nextContextLineMustMatch = true;\n      }\n      if (operation === ' ') {\n        nConsecutiveOldContextLines++;\n        patchedLines[patchedLinesLength] = lines[toPos];\n        if (compareLine(toPos + 1, lines[toPos], operation, content)) {\n          patchedLinesLength++;\n          lastContextLineMatched = true;\n          nextContextLineMustMatch = false;\n          toPos++;\n        } else {\n          if (nextContextLineMustMatch || !maxErrors) {\n            return null;\n          }\n\n          // Consider 3 possibilities in sequence:\n          // 1. lines contains a *substitution* not included in the patch context, or\n          // 2. lines contains an *insertion* not included in the patch context, or\n          // 3. lines contains a *deletion* not included in the patch context\n          // The first two options are of course only possible if the line from lines is non-null -\n          // i.e. only option 3 is possible if we've overrun the end of the old file.\n          return lines[toPos] && (applyHunk(hunkLines, toPos + 1, maxErrors - 1, hunkLinesI + 1, false, patchedLines, patchedLinesLength + 1) || applyHunk(hunkLines, toPos + 1, maxErrors - 1, hunkLinesI, false, patchedLines, patchedLinesLength + 1)) || applyHunk(hunkLines, toPos, maxErrors - 1, hunkLinesI + 1, false, patchedLines, patchedLinesLength);\n        }\n      }\n    }\n\n    // Before returning, trim any unmodified context lines off the end of patchedLines and reduce\n    // toPos (and thus oldLineLastI) accordingly. This allows later hunks to be applied to a region\n    // that starts in this hunk's trailing context.\n    patchedLinesLength -= nConsecutiveOldContextLines;\n    toPos -= nConsecutiveOldContextLines;\n    patchedLines.length = patchedLinesLength;\n    return {\n      patchedLines: patchedLines,\n      oldLineLastI: toPos - 1\n    };\n  }\n  var resultLines = [];\n\n  // Search best fit offsets for each hunk based on the previous ones\n  var prevHunkOffset = 0;\n  for (var _i = 0; _i < hunks.length; _i++) {\n    var hunk = hunks[_i];\n    var hunkResult = void 0;\n    var maxLine = lines.length - hunk.oldLines + fuzzFactor;\n    var toPos = void 0;\n    for (var maxErrors = 0; maxErrors <= fuzzFactor; maxErrors++) {\n      toPos = hunk.oldStart + prevHunkOffset - 1;\n      var iterator = distanceIterator(toPos, minLine, maxLine);\n      for (; toPos !== undefined; toPos = iterator()) {\n        hunkResult = applyHunk(hunk.lines, toPos, maxErrors);\n        if (hunkResult) {\n          break;\n        }\n      }\n      if (hunkResult) {\n        break;\n      }\n    }\n    if (!hunkResult) {\n      return false;\n    }\n\n    // Copy everything from the end of where we applied the last hunk to the start of this hunk\n    for (var _i2 = minLine; _i2 < toPos; _i2++) {\n      resultLines.push(lines[_i2]);\n    }\n\n    // Add the lines produced by applying the hunk:\n    for (var _i3 = 0; _i3 < hunkResult.patchedLines.length; _i3++) {\n      var _line = hunkResult.patchedLines[_i3];\n      resultLines.push(_line);\n    }\n\n    // Set lower text limit to end of the current hunk, so next ones don't try\n    // to fit over already patched text\n    minLine = hunkResult.oldLineLastI + 1;\n\n    // Note the offset between where the patch said the hunk should've applied and where we\n    // applied it, so we can adjust future hunks accordingly:\n    prevHunkOffset = toPos + 1 - hunk.oldStart;\n  }\n\n  // Copy over the rest of the lines from the old text\n  for (var _i4 = minLine; _i4 < lines.length; _i4++) {\n    resultLines.push(lines[_i4]);\n  }\n  return resultLines.join('\\n');\n}\n\n// Wrapper that supports multiple file patches via callbacks.\nfunction applyPatches(uniDiff, options) {\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n  var currentIndex = 0;\n  function processIndex() {\n    var index = uniDiff[currentIndex++];\n    if (!index) {\n      return options.complete();\n    }\n    options.loadFile(index, function (err, data) {\n      if (err) {\n        return options.complete(err);\n      }\n      var updatedContent = applyPatch(data, index, options);\n      options.patched(index, updatedContent, function (err) {\n        if (err) {\n          return options.complete(err);\n        }\n        processIndex();\n      });\n    });\n  }\n  processIndex();\n}\n\nfunction structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {\n  if (!options) {\n    options = {};\n  }\n  if (typeof options === 'function') {\n    options = {\n      callback: options\n    };\n  }\n  if (typeof options.context === 'undefined') {\n    options.context = 4;\n  }\n  if (options.newlineIsToken) {\n    throw new Error('newlineIsToken may not be used with patch-generation functions, only with diffing functions');\n  }\n  if (!options.callback) {\n    return diffLinesResultToPatch(diffLines(oldStr, newStr, options));\n  } else {\n    var _options = options,\n      _callback = _options.callback;\n    diffLines(oldStr, newStr, _objectSpread2(_objectSpread2({}, options), {}, {\n      callback: function callback(diff) {\n        var patch = diffLinesResultToPatch(diff);\n        _callback(patch);\n      }\n    }));\n  }\n  function diffLinesResultToPatch(diff) {\n    // STEP 1: Build up the patch with no \"\\ No newline at end of file\" lines and with the arrays\n    //         of lines containing trailing newline characters. We'll tidy up later...\n\n    if (!diff) {\n      return;\n    }\n    diff.push({\n      value: '',\n      lines: []\n    }); // Append an empty value to make cleanup easier\n\n    function contextLines(lines) {\n      return lines.map(function (entry) {\n        return ' ' + entry;\n      });\n    }\n    var hunks = [];\n    var oldRangeStart = 0,\n      newRangeStart = 0,\n      curRange = [],\n      oldLine = 1,\n      newLine = 1;\n    var _loop = function _loop() {\n      var current = diff[i],\n        lines = current.lines || splitLines(current.value);\n      current.lines = lines;\n      if (current.added || current.removed) {\n        var _curRange;\n        // If we have previous context, start with that\n        if (!oldRangeStart) {\n          var prev = diff[i - 1];\n          oldRangeStart = oldLine;\n          newRangeStart = newLine;\n          if (prev) {\n            curRange = options.context > 0 ? contextLines(prev.lines.slice(-options.context)) : [];\n            oldRangeStart -= curRange.length;\n            newRangeStart -= curRange.length;\n          }\n        }\n\n        // Output our changes\n        (_curRange = curRange).push.apply(_curRange, _toConsumableArray(lines.map(function (entry) {\n          return (current.added ? '+' : '-') + entry;\n        })));\n\n        // Track the updated file position\n        if (current.added) {\n          newLine += lines.length;\n        } else {\n          oldLine += lines.length;\n        }\n      } else {\n        // Identical context lines. Track line changes\n        if (oldRangeStart) {\n          // Close out any changes that have been output (or join overlapping)\n          if (lines.length <= options.context * 2 && i < diff.length - 2) {\n            var _curRange2;\n            // Overlapping\n            (_curRange2 = curRange).push.apply(_curRange2, _toConsumableArray(contextLines(lines)));\n          } else {\n            var _curRange3;\n            // end the range and output\n            var contextSize = Math.min(lines.length, options.context);\n            (_curRange3 = curRange).push.apply(_curRange3, _toConsumableArray(contextLines(lines.slice(0, contextSize))));\n            var _hunk = {\n              oldStart: oldRangeStart,\n              oldLines: oldLine - oldRangeStart + contextSize,\n              newStart: newRangeStart,\n              newLines: newLine - newRangeStart + contextSize,\n              lines: curRange\n            };\n            hunks.push(_hunk);\n            oldRangeStart = 0;\n            newRangeStart = 0;\n            curRange = [];\n          }\n        }\n        oldLine += lines.length;\n        newLine += lines.length;\n      }\n    };\n    for (var i = 0; i < diff.length; i++) {\n      _loop();\n    }\n\n    // Step 2: eliminate the trailing `\\n` from each line of each hunk, and, where needed, add\n    //         \"\\ No newline at end of file\".\n    for (var _i = 0, _hunks = hunks; _i < _hunks.length; _i++) {\n      var hunk = _hunks[_i];\n      for (var _i2 = 0; _i2 < hunk.lines.length; _i2++) {\n        if (hunk.lines[_i2].endsWith('\\n')) {\n          hunk.lines[_i2] = hunk.lines[_i2].slice(0, -1);\n        } else {\n          hunk.lines.splice(_i2 + 1, 0, '\\\\ No newline at end of file');\n          _i2++; // Skip the line we just added, then continue iterating\n        }\n      }\n    }\n    return {\n      oldFileName: oldFileName,\n      newFileName: newFileName,\n      oldHeader: oldHeader,\n      newHeader: newHeader,\n      hunks: hunks\n    };\n  }\n}\nfunction formatPatch(diff) {\n  if (Array.isArray(diff)) {\n    return diff.map(formatPatch).join('\\n');\n  }\n  var ret = [];\n  if (diff.oldFileName == diff.newFileName) {\n    ret.push('Index: ' + diff.oldFileName);\n  }\n  ret.push('===================================================================');\n  ret.push('--- ' + diff.oldFileName + (typeof diff.oldHeader === 'undefined' ? '' : '\\t' + diff.oldHeader));\n  ret.push('+++ ' + diff.newFileName + (typeof diff.newHeader === 'undefined' ? '' : '\\t' + diff.newHeader));\n  for (var i = 0; i < diff.hunks.length; i++) {\n    var hunk = diff.hunks[i];\n    // Unified Diff Format quirk: If the chunk size is 0,\n    // the first number is one lower than one would expect.\n    // https://www.artima.com/weblogs/viewpost.jsp?thread=164293\n    if (hunk.oldLines === 0) {\n      hunk.oldStart -= 1;\n    }\n    if (hunk.newLines === 0) {\n      hunk.newStart -= 1;\n    }\n    ret.push('@@ -' + hunk.oldStart + ',' + hunk.oldLines + ' +' + hunk.newStart + ',' + hunk.newLines + ' @@');\n    ret.push.apply(ret, hunk.lines);\n  }\n  return ret.join('\\n') + '\\n';\n}\nfunction createTwoFilesPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {\n  var _options2;\n  if (typeof options === 'function') {\n    options = {\n      callback: options\n    };\n  }\n  if (!((_options2 = options) !== null && _options2 !== void 0 && _options2.callback)) {\n    var patchObj = structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options);\n    if (!patchObj) {\n      return;\n    }\n    return formatPatch(patchObj);\n  } else {\n    var _options3 = options,\n      _callback2 = _options3.callback;\n    structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, _objectSpread2(_objectSpread2({}, options), {}, {\n      callback: function callback(patchObj) {\n        if (!patchObj) {\n          _callback2();\n        } else {\n          _callback2(formatPatch(patchObj));\n        }\n      }\n    }));\n  }\n}\nfunction createPatch(fileName, oldStr, newStr, oldHeader, newHeader, options) {\n  return createTwoFilesPatch(fileName, fileName, oldStr, newStr, oldHeader, newHeader, options);\n}\n\n/**\n * Split `text` into an array of lines, including the trailing newline character (where present)\n */\nfunction splitLines(text) {\n  var hasTrailingNl = text.endsWith('\\n');\n  var result = text.split('\\n').map(function (line) {\n    return line + '\\n';\n  });\n  if (hasTrailingNl) {\n    result.pop();\n  } else {\n    result.push(result.pop().slice(0, -1));\n  }\n  return result;\n}\n\nfunction arrayEqual(a, b) {\n  if (a.length !== b.length) {\n    return false;\n  }\n  return arrayStartsWith(a, b);\n}\nfunction arrayStartsWith(array, start) {\n  if (start.length > array.length) {\n    return false;\n  }\n  for (var i = 0; i < start.length; i++) {\n    if (start[i] !== array[i]) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction calcLineCount(hunk) {\n  var _calcOldNewLineCount = calcOldNewLineCount(hunk.lines),\n    oldLines = _calcOldNewLineCount.oldLines,\n    newLines = _calcOldNewLineCount.newLines;\n  if (oldLines !== undefined) {\n    hunk.oldLines = oldLines;\n  } else {\n    delete hunk.oldLines;\n  }\n  if (newLines !== undefined) {\n    hunk.newLines = newLines;\n  } else {\n    delete hunk.newLines;\n  }\n}\nfunction merge(mine, theirs, base) {\n  mine = loadPatch(mine, base);\n  theirs = loadPatch(theirs, base);\n  var ret = {};\n\n  // For index we just let it pass through as it doesn't have any necessary meaning.\n  // Leaving sanity checks on this to the API consumer that may know more about the\n  // meaning in their own context.\n  if (mine.index || theirs.index) {\n    ret.index = mine.index || theirs.index;\n  }\n  if (mine.newFileName || theirs.newFileName) {\n    if (!fileNameChanged(mine)) {\n      // No header or no change in ours, use theirs (and ours if theirs does not exist)\n      ret.oldFileName = theirs.oldFileName || mine.oldFileName;\n      ret.newFileName = theirs.newFileName || mine.newFileName;\n      ret.oldHeader = theirs.oldHeader || mine.oldHeader;\n      ret.newHeader = theirs.newHeader || mine.newHeader;\n    } else if (!fileNameChanged(theirs)) {\n      // No header or no change in theirs, use ours\n      ret.oldFileName = mine.oldFileName;\n      ret.newFileName = mine.newFileName;\n      ret.oldHeader = mine.oldHeader;\n      ret.newHeader = mine.newHeader;\n    } else {\n      // Both changed... figure it out\n      ret.oldFileName = selectField(ret, mine.oldFileName, theirs.oldFileName);\n      ret.newFileName = selectField(ret, mine.newFileName, theirs.newFileName);\n      ret.oldHeader = selectField(ret, mine.oldHeader, theirs.oldHeader);\n      ret.newHeader = selectField(ret, mine.newHeader, theirs.newHeader);\n    }\n  }\n  ret.hunks = [];\n  var mineIndex = 0,\n    theirsIndex = 0,\n    mineOffset = 0,\n    theirsOffset = 0;\n  while (mineIndex < mine.hunks.length || theirsIndex < theirs.hunks.length) {\n    var mineCurrent = mine.hunks[mineIndex] || {\n        oldStart: Infinity\n      },\n      theirsCurrent = theirs.hunks[theirsIndex] || {\n        oldStart: Infinity\n      };\n    if (hunkBefore(mineCurrent, theirsCurrent)) {\n      // This patch does not overlap with any of the others, yay.\n      ret.hunks.push(cloneHunk(mineCurrent, mineOffset));\n      mineIndex++;\n      theirsOffset += mineCurrent.newLines - mineCurrent.oldLines;\n    } else if (hunkBefore(theirsCurrent, mineCurrent)) {\n      // This patch does not overlap with any of the others, yay.\n      ret.hunks.push(cloneHunk(theirsCurrent, theirsOffset));\n      theirsIndex++;\n      mineOffset += theirsCurrent.newLines - theirsCurrent.oldLines;\n    } else {\n      // Overlap, merge as best we can\n      var mergedHunk = {\n        oldStart: Math.min(mineCurrent.oldStart, theirsCurrent.oldStart),\n        oldLines: 0,\n        newStart: Math.min(mineCurrent.newStart + mineOffset, theirsCurrent.oldStart + theirsOffset),\n        newLines: 0,\n        lines: []\n      };\n      mergeLines(mergedHunk, mineCurrent.oldStart, mineCurrent.lines, theirsCurrent.oldStart, theirsCurrent.lines);\n      theirsIndex++;\n      mineIndex++;\n      ret.hunks.push(mergedHunk);\n    }\n  }\n  return ret;\n}\nfunction loadPatch(param, base) {\n  if (typeof param === 'string') {\n    if (/^@@/m.test(param) || /^Index:/m.test(param)) {\n      return parsePatch(param)[0];\n    }\n    if (!base) {\n      throw new Error('Must provide a base reference or pass in a patch');\n    }\n    return structuredPatch(undefined, undefined, base, param);\n  }\n  return param;\n}\nfunction fileNameChanged(patch) {\n  return patch.newFileName && patch.newFileName !== patch.oldFileName;\n}\nfunction selectField(index, mine, theirs) {\n  if (mine === theirs) {\n    return mine;\n  } else {\n    index.conflict = true;\n    return {\n      mine: mine,\n      theirs: theirs\n    };\n  }\n}\nfunction hunkBefore(test, check) {\n  return test.oldStart < check.oldStart && test.oldStart + test.oldLines < check.oldStart;\n}\nfunction cloneHunk(hunk, offset) {\n  return {\n    oldStart: hunk.oldStart,\n    oldLines: hunk.oldLines,\n    newStart: hunk.newStart + offset,\n    newLines: hunk.newLines,\n    lines: hunk.lines\n  };\n}\nfunction mergeLines(hunk, mineOffset, mineLines, theirOffset, theirLines) {\n  // This will generally result in a conflicted hunk, but there are cases where the context\n  // is the only overlap where we can successfully merge the content here.\n  var mine = {\n      offset: mineOffset,\n      lines: mineLines,\n      index: 0\n    },\n    their = {\n      offset: theirOffset,\n      lines: theirLines,\n      index: 0\n    };\n\n  // Handle any leading content\n  insertLeading(hunk, mine, their);\n  insertLeading(hunk, their, mine);\n\n  // Now in the overlap content. Scan through and select the best changes from each.\n  while (mine.index < mine.lines.length && their.index < their.lines.length) {\n    var mineCurrent = mine.lines[mine.index],\n      theirCurrent = their.lines[their.index];\n    if ((mineCurrent[0] === '-' || mineCurrent[0] === '+') && (theirCurrent[0] === '-' || theirCurrent[0] === '+')) {\n      // Both modified ...\n      mutualChange(hunk, mine, their);\n    } else if (mineCurrent[0] === '+' && theirCurrent[0] === ' ') {\n      var _hunk$lines;\n      // Mine inserted\n      (_hunk$lines = hunk.lines).push.apply(_hunk$lines, _toConsumableArray(collectChange(mine)));\n    } else if (theirCurrent[0] === '+' && mineCurrent[0] === ' ') {\n      var _hunk$lines2;\n      // Theirs inserted\n      (_hunk$lines2 = hunk.lines).push.apply(_hunk$lines2, _toConsumableArray(collectChange(their)));\n    } else if (mineCurrent[0] === '-' && theirCurrent[0] === ' ') {\n      // Mine removed or edited\n      removal(hunk, mine, their);\n    } else if (theirCurrent[0] === '-' && mineCurrent[0] === ' ') {\n      // Their removed or edited\n      removal(hunk, their, mine, true);\n    } else if (mineCurrent === theirCurrent) {\n      // Context identity\n      hunk.lines.push(mineCurrent);\n      mine.index++;\n      their.index++;\n    } else {\n      // Context mismatch\n      conflict(hunk, collectChange(mine), collectChange(their));\n    }\n  }\n\n  // Now push anything that may be remaining\n  insertTrailing(hunk, mine);\n  insertTrailing(hunk, their);\n  calcLineCount(hunk);\n}\nfunction mutualChange(hunk, mine, their) {\n  var myChanges = collectChange(mine),\n    theirChanges = collectChange(their);\n  if (allRemoves(myChanges) && allRemoves(theirChanges)) {\n    // Special case for remove changes that are supersets of one another\n    if (arrayStartsWith(myChanges, theirChanges) && skipRemoveSuperset(their, myChanges, myChanges.length - theirChanges.length)) {\n      var _hunk$lines3;\n      (_hunk$lines3 = hunk.lines).push.apply(_hunk$lines3, _toConsumableArray(myChanges));\n      return;\n    } else if (arrayStartsWith(theirChanges, myChanges) && skipRemoveSuperset(mine, theirChanges, theirChanges.length - myChanges.length)) {\n      var _hunk$lines4;\n      (_hunk$lines4 = hunk.lines).push.apply(_hunk$lines4, _toConsumableArray(theirChanges));\n      return;\n    }\n  } else if (arrayEqual(myChanges, theirChanges)) {\n    var _hunk$lines5;\n    (_hunk$lines5 = hunk.lines).push.apply(_hunk$lines5, _toConsumableArray(myChanges));\n    return;\n  }\n  conflict(hunk, myChanges, theirChanges);\n}\nfunction removal(hunk, mine, their, swap) {\n  var myChanges = collectChange(mine),\n    theirChanges = collectContext(their, myChanges);\n  if (theirChanges.merged) {\n    var _hunk$lines6;\n    (_hunk$lines6 = hunk.lines).push.apply(_hunk$lines6, _toConsumableArray(theirChanges.merged));\n  } else {\n    conflict(hunk, swap ? theirChanges : myChanges, swap ? myChanges : theirChanges);\n  }\n}\nfunction conflict(hunk, mine, their) {\n  hunk.conflict = true;\n  hunk.lines.push({\n    conflict: true,\n    mine: mine,\n    theirs: their\n  });\n}\nfunction insertLeading(hunk, insert, their) {\n  while (insert.offset < their.offset && insert.index < insert.lines.length) {\n    var line = insert.lines[insert.index++];\n    hunk.lines.push(line);\n    insert.offset++;\n  }\n}\nfunction insertTrailing(hunk, insert) {\n  while (insert.index < insert.lines.length) {\n    var line = insert.lines[insert.index++];\n    hunk.lines.push(line);\n  }\n}\nfunction collectChange(state) {\n  var ret = [],\n    operation = state.lines[state.index][0];\n  while (state.index < state.lines.length) {\n    var line = state.lines[state.index];\n\n    // Group additions that are immediately after subtractions and treat them as one \"atomic\" modify change.\n    if (operation === '-' && line[0] === '+') {\n      operation = '+';\n    }\n    if (operation === line[0]) {\n      ret.push(line);\n      state.index++;\n    } else {\n      break;\n    }\n  }\n  return ret;\n}\nfunction collectContext(state, matchChanges) {\n  var changes = [],\n    merged = [],\n    matchIndex = 0,\n    contextChanges = false,\n    conflicted = false;\n  while (matchIndex < matchChanges.length && state.index < state.lines.length) {\n    var change = state.lines[state.index],\n      match = matchChanges[matchIndex];\n\n    // Once we've hit our add, then we are done\n    if (match[0] === '+') {\n      break;\n    }\n    contextChanges = contextChanges || change[0] !== ' ';\n    merged.push(match);\n    matchIndex++;\n\n    // Consume any additions in the other block as a conflict to attempt\n    // to pull in the remaining context after this\n    if (change[0] === '+') {\n      conflicted = true;\n      while (change[0] === '+') {\n        changes.push(change);\n        change = state.lines[++state.index];\n      }\n    }\n    if (match.substr(1) === change.substr(1)) {\n      changes.push(change);\n      state.index++;\n    } else {\n      conflicted = true;\n    }\n  }\n  if ((matchChanges[matchIndex] || '')[0] === '+' && contextChanges) {\n    conflicted = true;\n  }\n  if (conflicted) {\n    return changes;\n  }\n  while (matchIndex < matchChanges.length) {\n    merged.push(matchChanges[matchIndex++]);\n  }\n  return {\n    merged: merged,\n    changes: changes\n  };\n}\nfunction allRemoves(changes) {\n  return changes.reduce(function (prev, change) {\n    return prev && change[0] === '-';\n  }, true);\n}\nfunction skipRemoveSuperset(state, removeChanges, delta) {\n  for (var i = 0; i < delta; i++) {\n    var changeContent = removeChanges[removeChanges.length - delta + i].substr(1);\n    if (state.lines[state.index + i] !== ' ' + changeContent) {\n      return false;\n    }\n  }\n  state.index += delta;\n  return true;\n}\nfunction calcOldNewLineCount(lines) {\n  var oldLines = 0;\n  var newLines = 0;\n  lines.forEach(function (line) {\n    if (typeof line !== 'string') {\n      var myCount = calcOldNewLineCount(line.mine);\n      var theirCount = calcOldNewLineCount(line.theirs);\n      if (oldLines !== undefined) {\n        if (myCount.oldLines === theirCount.oldLines) {\n          oldLines += myCount.oldLines;\n        } else {\n          oldLines = undefined;\n        }\n      }\n      if (newLines !== undefined) {\n        if (myCount.newLines === theirCount.newLines) {\n          newLines += myCount.newLines;\n        } else {\n          newLines = undefined;\n        }\n      }\n    } else {\n      if (newLines !== undefined && (line[0] === '+' || line[0] === ' ')) {\n        newLines++;\n      }\n      if (oldLines !== undefined && (line[0] === '-' || line[0] === ' ')) {\n        oldLines++;\n      }\n    }\n  });\n  return {\n    oldLines: oldLines,\n    newLines: newLines\n  };\n}\n\nfunction reversePatch(structuredPatch) {\n  if (Array.isArray(structuredPatch)) {\n    return structuredPatch.map(reversePatch).reverse();\n  }\n  return _objectSpread2(_objectSpread2({}, structuredPatch), {}, {\n    oldFileName: structuredPatch.newFileName,\n    oldHeader: structuredPatch.newHeader,\n    newFileName: structuredPatch.oldFileName,\n    newHeader: structuredPatch.oldHeader,\n    hunks: structuredPatch.hunks.map(function (hunk) {\n      return {\n        oldLines: hunk.newLines,\n        oldStart: hunk.newStart,\n        newLines: hunk.oldLines,\n        newStart: hunk.oldStart,\n        lines: hunk.lines.map(function (l) {\n          if (l.startsWith('-')) {\n            return \"+\".concat(l.slice(1));\n          }\n          if (l.startsWith('+')) {\n            return \"-\".concat(l.slice(1));\n          }\n          return l;\n        })\n      };\n    })\n  });\n}\n\n// See: http://code.google.com/p/google-diff-match-patch/wiki/API\nfunction convertChangesToDMP(changes) {\n  var ret = [],\n    change,\n    operation;\n  for (var i = 0; i < changes.length; i++) {\n    change = changes[i];\n    if (change.added) {\n      operation = 1;\n    } else if (change.removed) {\n      operation = -1;\n    } else {\n      operation = 0;\n    }\n    ret.push([operation, change.value]);\n  }\n  return ret;\n}\n\nfunction convertChangesToXML(changes) {\n  var ret = [];\n  for (var i = 0; i < changes.length; i++) {\n    var change = changes[i];\n    if (change.added) {\n      ret.push('<ins>');\n    } else if (change.removed) {\n      ret.push('<del>');\n    }\n    ret.push(escapeHTML(change.value));\n    if (change.added) {\n      ret.push('</ins>');\n    } else if (change.removed) {\n      ret.push('</del>');\n    }\n  }\n  return ret.join('');\n}\nfunction escapeHTML(s) {\n  var n = s;\n  n = n.replace(/&/g, '&amp;');\n  n = n.replace(/</g, '&lt;');\n  n = n.replace(/>/g, '&gt;');\n  n = n.replace(/\"/g, '&quot;');\n  return n;\n}\n\nexport { Diff, applyPatch, applyPatches, canonicalize, convertChangesToDMP, convertChangesToXML, createPatch, createTwoFilesPatch, diffArrays, diffChars, diffCss, diffJson, diffLines, diffSentences, diffTrimmedLines, diffWords, diffWordsWithSpace, formatPatch, merge, parsePatch, reversePatch, structuredPatch };\n"],"names":["Diff","oldString","newString","_options$timeout","options","callback","self","done","value","newLen","oldLen","editLength","maxEditLength","maxExecutionTime","abortAfterTimestamp","bestPath","newPos","buildValues","minDiagonalToConsider","maxDiagonalToConsider","execEditLength","diagonalPath","basePath","removePath","addPath","canAdd","addPathNewPos","canRemove","exec","ret","path","added","removed","oldPosInc","last","oldPos","commonCount","left","right","array","i","chars","changeObjects","diff","lastComponent","useLongestToken","components","nextComponent","componentPos","componentLen","component","oldValue","longestCommonPrefix","str1","str2","longestCommonSuffix","replacePrefix","string","oldPrefix","newPrefix","replaceSuffix","oldSuffix","newSuffix","removePrefix","removeSuffix","maximumOverlap","string1","string2","overlapCount","a","b","startA","endB","map","k","j","extendedWordChars","tokenizeIncludingWhitespace","wordDiff","parts","segment","tokens","prevPart","part","token","changes","lastKeep","insertion","deletion","change","dedupeWhitespaceInChangeObjects","diffWords","oldStr","newStr","diffWordsWithSpace","startKeep","endKeep","oldWsPrefix","oldWsSuffix","newWsPrefix","newWsSuffix","commonWsPrefix","commonWsSuffix","newWsFull","delWsStart","delWsEnd","newWsStart","newWsEnd","endKeepWsPrefix","deletionWsSuffix","overlap","startKeepWsSuffix","deletionWsPrefix","_overlap","wordWithSpaceDiff","regex","lineDiff","retLines","linesAndNewlines","line","sentenceDiff","cssDiff","_typeof","o","jsonDiff","undefinedReplacement","_options$stringifyRep","stringifyReplacer","v","canonicalize","obj","stack","replacementStack","replacer","key","canonicalizedObj","sortedKeys","_key","arrayDiff"],"mappings":"AAAA,SAASA,IAAO;AAAA;AAChBA,EAAK,YAAY;AAAA,EACf,MAAM,SAAcC,GAAWC,GAAW;AACxC,QAAIC,GACAC,IAAU,UAAU,SAAS,KAAK,UAAU,CAAC,MAAM,SAAY,UAAU,CAAC,IAAI,CAAE,GAChFC,IAAWD,EAAQ;AACvB,IAAI,OAAOA,KAAY,eACrBC,IAAWD,GACXA,IAAU,CAAE;AAEd,QAAIE,IAAO;AACX,aAASC,EAAKC,GAAO;AAEnB,aADAA,IAAQF,EAAK,YAAYE,GAAOJ,CAAO,GACnCC,KACF,WAAW,WAAY;AACrB,QAAAA,EAASG,CAAK;AAAA,MACf,GAAE,CAAC,GACG,MAEAA;AAAA,IAEf;AAGI,IAAAP,IAAY,KAAK,UAAUA,GAAWG,CAAO,GAC7CF,IAAY,KAAK,UAAUA,GAAWE,CAAO,GAC7CH,IAAY,KAAK,YAAY,KAAK,SAASA,GAAWG,CAAO,CAAC,GAC9DF,IAAY,KAAK,YAAY,KAAK,SAASA,GAAWE,CAAO,CAAC;AAC9D,QAAIK,IAASP,EAAU,QACrBQ,IAAST,EAAU,QACjBU,IAAa,GACbC,IAAgBH,IAASC;AAC7B,IAAIN,EAAQ,iBAAiB,SAC3BQ,IAAgB,KAAK,IAAIA,GAAeR,EAAQ,aAAa;AAE/D,QAAIS,KAAoBV,IAAmBC,EAAQ,aAAa,QAAQD,MAAqB,SAASA,IAAmB,OACrHW,IAAsB,KAAK,IAAG,IAAKD,GACnCE,IAAW,CAAC;AAAA,MACd,QAAQ;AAAA,MACR,eAAe;AAAA,IACrB,CAAK,GAGGC,IAAS,KAAK,cAAcD,EAAS,CAAC,GAAGb,GAAWD,GAAW,GAAGG,CAAO;AAC7E,QAAIW,EAAS,CAAC,EAAE,SAAS,KAAKL,KAAUM,IAAS,KAAKP;AAEpD,aAAOF,EAAKU,EAAYX,GAAMS,EAAS,CAAC,EAAE,eAAeb,GAAWD,GAAWK,EAAK,eAAe,CAAC;AAoBtG,QAAIY,IAAwB,QAC1BC,IAAwB;AAG1B,aAASC,IAAiB;AACxB,eAASC,IAAe,KAAK,IAAIH,GAAuB,CAACP,CAAU,GAAGU,KAAgB,KAAK,IAAIF,GAAuBR,CAAU,GAAGU,KAAgB,GAAG;AACpJ,YAAIC,IAAW,QACXC,IAAaR,EAASM,IAAe,CAAC,GACxCG,IAAUT,EAASM,IAAe,CAAC;AACrC,QAAIE,MAEFR,EAASM,IAAe,CAAC,IAAI;AAE/B,YAAII,IAAS;AACb,YAAID,GAAS;AAEX,cAAIE,IAAgBF,EAAQ,SAASH;AACrC,UAAAI,IAASD,KAAW,KAAKE,KAAiBA,IAAgBjB;AAAA,QACpE;AACQ,YAAIkB,IAAYJ,KAAcA,EAAW,SAAS,IAAIb;AACtD,YAAI,CAACe,KAAU,CAACE,GAAW;AAEzB,UAAAZ,EAASM,CAAY,IAAI;AACzB;AAAA,QACV;AAWQ,YANI,CAACM,KAAaF,KAAUF,EAAW,SAASC,EAAQ,SACtDF,IAAWhB,EAAK,UAAUkB,GAAS,IAAM,IAAO,GAAGpB,CAAO,IAE1DkB,IAAWhB,EAAK,UAAUiB,GAAY,IAAO,IAAM,GAAGnB,CAAO,GAE/DY,IAASV,EAAK,cAAcgB,GAAUpB,GAAWD,GAAWoB,GAAcjB,CAAO,GAC7EkB,EAAS,SAAS,KAAKZ,KAAUM,IAAS,KAAKP;AAEjD,iBAAOF,EAAKU,EAAYX,GAAMgB,EAAS,eAAepB,GAAWD,GAAWK,EAAK,eAAe,CAAC;AAEjG,QAAAS,EAASM,CAAY,IAAIC,GACrBA,EAAS,SAAS,KAAKZ,MACzBS,IAAwB,KAAK,IAAIA,GAAuBE,IAAe,CAAC,IAEtEL,IAAS,KAAKP,MAChBS,IAAwB,KAAK,IAAIA,GAAuBG,IAAe,CAAC;AAAA,MAGpF;AACM,MAAAV;AAAA,IACN;AAMI,QAAIN;AACF,OAAC,SAASuB,IAAO;AACf,mBAAW,WAAY;AACrB,cAAIjB,IAAaC,KAAiB,KAAK,IAAG,IAAKE;AAC7C,mBAAOT,EAAU;AAEnB,UAAKe,EAAc,KACjBQ,EAAM;AAAA,QAET,GAAE,CAAC;AAAA,MACZ,GAAU;AAAA;AAEJ,aAAOjB,KAAcC,KAAiB,KAAK,IAAG,KAAME,KAAqB;AACvE,YAAIe,IAAMT,EAAgB;AAC1B,YAAIS;AACF,iBAAOA;AAAA,MAEjB;AAAA,EAEG;AAAA,EACD,WAAW,SAAmBC,GAAMC,GAAOC,GAASC,GAAW7B,GAAS;AACtE,QAAI8B,IAAOJ,EAAK;AAChB,WAAII,KAAQ,CAAC9B,EAAQ,qBAAqB8B,EAAK,UAAUH,KAASG,EAAK,YAAYF,IAC1E;AAAA,MACL,QAAQF,EAAK,SAASG;AAAA,MACtB,eAAe;AAAA,QACb,OAAOC,EAAK,QAAQ;AAAA,QACpB,OAAOH;AAAA,QACP,SAASC;AAAA,QACT,mBAAmBE,EAAK;AAAA,MAClC;AAAA,IACO,IAEM;AAAA,MACL,QAAQJ,EAAK,SAASG;AAAA,MACtB,eAAe;AAAA,QACb,OAAO;AAAA,QACP,OAAOF;AAAA,QACP,SAASC;AAAA,QACT,mBAAmBE;AAAA,MAC7B;AAAA,IACO;AAAA,EAEJ;AAAA,EACD,eAAe,SAAuBZ,GAAUpB,GAAWD,GAAWoB,GAAcjB,GAAS;AAM3F,aALIK,IAASP,EAAU,QACrBQ,IAAST,EAAU,QACnBkC,IAASb,EAAS,QAClBN,IAASmB,IAASd,GAClBe,IAAc,GACTpB,IAAS,IAAIP,KAAU0B,IAAS,IAAIzB,KAAU,KAAK,OAAOT,EAAUkC,IAAS,CAAC,GAAGjC,EAAUc,IAAS,CAAC,GAAGZ,CAAO;AACpH,MAAAY,KACAmB,KACAC,KACIhC,EAAQ,sBACVkB,EAAS,gBAAgB;AAAA,QACvB,OAAO;AAAA,QACP,mBAAmBA,EAAS;AAAA,QAC5B,OAAO;AAAA,QACP,SAAS;AAAA,MACV;AAGL,WAAIc,KAAe,CAAChC,EAAQ,sBAC1BkB,EAAS,gBAAgB;AAAA,MACvB,OAAOc;AAAA,MACP,mBAAmBd,EAAS;AAAA,MAC5B,OAAO;AAAA,MACP,SAAS;AAAA,IACV,IAEHA,EAAS,SAASa,GACXnB;AAAA,EACR;AAAA,EACD,QAAQ,SAAgBqB,GAAMC,GAAOlC,GAAS;AAC5C,WAAIA,EAAQ,aACHA,EAAQ,WAAWiC,GAAMC,CAAK,IAE9BD,MAASC,KAASlC,EAAQ,cAAciC,EAAK,YAAW,MAAOC,EAAM,YAAa;AAAA,EAE5F;AAAA,EACD,aAAa,SAAqBC,GAAO;AAEvC,aADIV,IAAM,CAAE,GACHW,IAAI,GAAGA,IAAID,EAAM,QAAQC;AAChC,MAAID,EAAMC,CAAC,KACTX,EAAI,KAAKU,EAAMC,CAAC,CAAC;AAGrB,WAAOX;AAAA,EACR;AAAA,EACD,WAAW,SAAmBrB,GAAO;AACnC,WAAOA;AAAA,EACR;AAAA,EACD,UAAU,SAAkBA,GAAO;AACjC,WAAO,MAAM,KAAKA,CAAK;AAAA,EACxB;AAAA,EACD,MAAM,SAAciC,GAAO;AACzB,WAAOA,EAAM,KAAK,EAAE;AAAA,EACrB;AAAA,EACD,aAAa,SAAqBC,GAAe;AAC/C,WAAOA;AAAA,EACX;AACA;AACA,SAASzB,EAAY0B,GAAMC,GAAe1C,GAAWD,GAAW4C,GAAiB;AAK/E,WAFIC,IAAa,CAAE,GACfC,GACGH;AACL,IAAAE,EAAW,KAAKF,CAAa,GAC7BG,IAAgBH,EAAc,mBAC9B,OAAOA,EAAc,mBACrBA,IAAgBG;AAElB,EAAAD,EAAW,QAAS;AAKpB,WAJIE,IAAe,GACjBC,IAAeH,EAAW,QAC1B9B,IAAS,GACTmB,IAAS,GACJa,IAAeC,GAAcD,KAAgB;AAClD,QAAIE,IAAYJ,EAAWE,CAAY;AACvC,QAAKE,EAAU;AAkBb,MAAAA,EAAU,QAAQP,EAAK,KAAK1C,EAAU,MAAMkC,GAAQA,IAASe,EAAU,KAAK,CAAC,GAC7Ef,KAAUe,EAAU;AAAA,SAnBE;AACtB,UAAI,CAACA,EAAU,SAASL,GAAiB;AACvC,YAAIrC,IAAQN,EAAU,MAAMc,GAAQA,IAASkC,EAAU,KAAK;AAC5D,QAAA1C,IAAQA,EAAM,IAAI,SAAUA,GAAOgC,GAAG;AACpC,cAAIW,IAAWlD,EAAUkC,IAASK,CAAC;AACnC,iBAAOW,EAAS,SAAS3C,EAAM,SAAS2C,IAAW3C;AAAA,QAC7D,CAAS,GACD0C,EAAU,QAAQP,EAAK,KAAKnC,CAAK;AAAA,MACzC;AACQ,QAAA0C,EAAU,QAAQP,EAAK,KAAKzC,EAAU,MAAMc,GAAQA,IAASkC,EAAU,KAAK,CAAC;AAE/E,MAAAlC,KAAUkC,EAAU,OAGfA,EAAU,UACbf,KAAUe,EAAU;AAAA,IAE5B;AAAA,EAIA;AACE,SAAOJ;AACT;AAOA,SAASM,EAAoBC,GAAMC,GAAM;AACvC,MAAId;AACJ,OAAKA,IAAI,GAAGA,IAAIa,EAAK,UAAUb,IAAIc,EAAK,QAAQd;AAC9C,QAAIa,EAAKb,CAAC,KAAKc,EAAKd,CAAC;AACnB,aAAOa,EAAK,MAAM,GAAGb,CAAC;AAG1B,SAAOa,EAAK,MAAM,GAAGb,CAAC;AACxB;AACA,SAASe,EAAoBF,GAAMC,GAAM;AACvC,MAAId;AAKJ,MAAI,CAACa,KAAQ,CAACC,KAAQD,EAAKA,EAAK,SAAS,CAAC,KAAKC,EAAKA,EAAK,SAAS,CAAC;AACjE,WAAO;AAET,OAAKd,IAAI,GAAGA,IAAIa,EAAK,UAAUb,IAAIc,EAAK,QAAQd;AAC9C,QAAIa,EAAKA,EAAK,UAAUb,IAAI,EAAE,KAAKc,EAAKA,EAAK,UAAUd,IAAI,EAAE;AAC3D,aAAOa,EAAK,MAAM,CAACb,CAAC;AAGxB,SAAOa,EAAK,MAAM,CAACb,CAAC;AACtB;AACA,SAASgB,EAAcC,GAAQC,GAAWC,GAAW;AACnD,MAAIF,EAAO,MAAM,GAAGC,EAAU,MAAM,KAAKA;AACvC,UAAM,MAAM,UAAU,OAAO,KAAK,UAAUD,CAAM,GAAG,6BAA6B,EAAE,OAAO,KAAK,UAAUC,CAAS,GAAG,iBAAiB,CAAC;AAE1I,SAAOC,IAAYF,EAAO,MAAMC,EAAU,MAAM;AAClD;AACA,SAASE,EAAcH,GAAQI,GAAWC,GAAW;AACnD,MAAI,CAACD;AACH,WAAOJ,IAASK;AAElB,MAAIL,EAAO,MAAM,CAACI,EAAU,MAAM,KAAKA;AACrC,UAAM,MAAM,UAAU,OAAO,KAAK,UAAUJ,CAAM,GAAG,2BAA2B,EAAE,OAAO,KAAK,UAAUI,CAAS,GAAG,iBAAiB,CAAC;AAExI,SAAOJ,EAAO,MAAM,GAAG,CAACI,EAAU,MAAM,IAAIC;AAC9C;AACA,SAASC,EAAaN,GAAQC,GAAW;AACvC,SAAOF,EAAcC,GAAQC,GAAW,EAAE;AAC5C;AACA,SAASM,EAAaP,GAAQI,GAAW;AACvC,SAAOD,EAAcH,GAAQI,GAAW,EAAE;AAC5C;AACA,SAASI,EAAeC,GAASC,GAAS;AACxC,SAAOA,EAAQ,MAAM,GAAGC,EAAaF,GAASC,CAAO,CAAC;AACxD;AAGA,SAASC,EAAaC,GAAGC,GAAG;AAE1B,MAAIC,IAAS;AACb,EAAIF,EAAE,SAASC,EAAE,WACfC,IAASF,EAAE,SAASC,EAAE;AAExB,MAAIE,IAAOF,EAAE;AACb,EAAID,EAAE,SAASC,EAAE,WACfE,IAAOH,EAAE;AAKX,MAAII,IAAM,MAAMD,CAAI,GAChBE,IAAI;AACR,EAAAD,EAAI,CAAC,IAAI;AACT,WAASE,IAAI,GAAGA,IAAIH,GAAMG,KAAK;AAM7B,SALIL,EAAEK,CAAC,KAAKL,EAAEI,CAAC,IACbD,EAAIE,CAAC,IAAIF,EAAIC,CAAC,IAEdD,EAAIE,CAAC,IAAID,GAEJA,IAAI,KAAKJ,EAAEK,CAAC,KAAKL,EAAEI,CAAC;AACzB,MAAAA,IAAID,EAAIC,CAAC;AAEX,IAAIJ,EAAEK,CAAC,KAAKL,EAAEI,CAAC,KACbA;AAAA,EAEN;AAEE,EAAAA,IAAI;AACJ,WAASlC,IAAI+B,GAAQ/B,IAAI6B,EAAE,QAAQ7B,KAAK;AACtC,WAAOkC,IAAI,KAAKL,EAAE7B,CAAC,KAAK8B,EAAEI,CAAC;AACzB,MAAAA,IAAID,EAAIC,CAAC;AAEX,IAAIL,EAAE7B,CAAC,KAAK8B,EAAEI,CAAC,KACbA;AAAA,EAEN;AACE,SAAOA;AACT;AAkCA,IAAIE,IAAoB,iHA2BpBC,IAA8B,IAAI,OAAO,IAAI,OAAOD,GAAmB,YAAY,EAAE,OAAOA,GAAmB,GAAG,GAAG,IAAI,GACzHE,IAAW,IAAI9E,EAAM;AACzB8E,EAAS,SAAS,SAAUzC,GAAMC,GAAOlC,GAAS;AAChD,SAAIA,EAAQ,eACViC,IAAOA,EAAK,YAAa,GACzBC,IAAQA,EAAM,YAAa,IAEtBD,EAAK,WAAWC,EAAM,KAAM;AACrC;AACAwC,EAAS,WAAW,SAAUtE,GAAO;AACnC,MAAIJ,IAAU,UAAU,SAAS,KAAK,UAAU,CAAC,MAAM,SAAY,UAAU,CAAC,IAAI,CAAE,GAChF2E;AACJ,MAAI3E,EAAQ,eAAe;AACzB,QAAIA,EAAQ,cAAc,gBAAe,EAAG,eAAe;AACzD,YAAM,IAAI,MAAM,wDAAwD;AAE1E,IAAA2E,IAAQ,MAAM,KAAK3E,EAAQ,cAAc,QAAQI,CAAK,GAAG,SAAUwE,GAAS;AAC1E,aAAOA,EAAQ;AAAA,IACrB,CAAK;AAAA,EACL;AACI,IAAAD,IAAQvE,EAAM,MAAMqE,CAA2B,KAAK,CAAE;AAExD,MAAII,IAAS,CAAE,GACXC,IAAW;AACf,SAAAH,EAAM,QAAQ,SAAUI,GAAM;AAC5B,IAAI,KAAK,KAAKA,CAAI,IACZD,KAAY,OACdD,EAAO,KAAKE,CAAI,IAEhBF,EAAO,KAAKA,EAAO,IAAG,IAAKE,CAAI,IAExB,KAAK,KAAKD,CAAQ,IACvBD,EAAOA,EAAO,SAAS,CAAC,KAAKC,IAC/BD,EAAO,KAAKA,EAAO,IAAG,IAAKE,CAAI,IAE/BF,EAAO,KAAKC,IAAWC,CAAI,IAG7BF,EAAO,KAAKE,CAAI,GAElBD,IAAWC;AAAA,EACf,CAAG,GACMF;AACT;AACAH,EAAS,OAAO,SAAUG,GAAQ;AAMhC,SAAOA,EAAO,IAAI,SAAUG,GAAO5C,GAAG;AACpC,WAAIA,KAAK,IACA4C,IAEAA,EAAM,QAAQ,QAAQ,EAAE;AAAA,EAErC,CAAG,EAAE,KAAK,EAAE;AACZ;AACAN,EAAS,cAAc,SAAUO,GAASjF,GAAS;AACjD,MAAI,CAACiF,KAAWjF,EAAQ;AACtB,WAAOiF;AAET,MAAIC,IAAW,MAGXC,IAAY,MACZC,IAAW;AACf,SAAAH,EAAQ,QAAQ,SAAUI,GAAQ;AAChC,IAAIA,EAAO,QACTF,IAAYE,IACHA,EAAO,UAChBD,IAAWC,MAEPF,KAAaC,MAEfE,EAAgCJ,GAAUE,GAAUD,GAAWE,CAAM,GAEvEH,IAAWG,GACXF,IAAY,MACZC,IAAW;AAAA,EAEjB,CAAG,IACGD,KAAaC,MACfE,EAAgCJ,GAAUE,GAAUD,GAAW,IAAI,GAE9DF;AACT;AACA,SAASM,EAAUC,GAAQC,GAAQzF,GAAS;AAK1C,SAAuDA,GAAQ,oBAAqB,QAAQ,CAACA,EAAQ,mBAC5F0F,EAAmBF,GAAQC,GAAQzF,CAAO,IAE5C0E,EAAS,KAAKc,GAAQC,GAAQzF,CAAO;AAC9C;AACA,SAASsF,EAAgCK,GAAWP,GAAUD,GAAWS,GAAS;AA2ChF,MAAIR,KAAYD,GAAW;AACzB,QAAIU,IAAcT,EAAS,MAAM,MAAM,MAAM,EAAE,CAAC,GAC5CU,IAAcV,EAAS,MAAM,MAAM,MAAM,EAAE,CAAC,GAC5CW,IAAcZ,EAAU,MAAM,MAAM,MAAM,EAAE,CAAC,GAC7Ca,IAAcb,EAAU,MAAM,MAAM,MAAM,EAAE,CAAC;AACjD,QAAIQ,GAAW;AACb,UAAIM,IAAiBjD,EAAoB6C,GAAaE,CAAW;AACjE,MAAAJ,EAAU,QAAQnC,EAAcmC,EAAU,OAAOI,GAAaE,CAAc,GAC5Eb,EAAS,QAAQzB,EAAayB,EAAS,OAAOa,CAAc,GAC5Dd,EAAU,QAAQxB,EAAawB,EAAU,OAAOc,CAAc;AAAA,IACpE;AACI,QAAIL,GAAS;AACX,UAAIM,IAAiB/C,EAAoB2C,GAAaE,CAAW;AACjE,MAAAJ,EAAQ,QAAQxC,EAAcwC,EAAQ,OAAOI,GAAaE,CAAc,GACxEd,EAAS,QAAQxB,EAAawB,EAAS,OAAOc,CAAc,GAC5Df,EAAU,QAAQvB,EAAauB,EAAU,OAAOe,CAAc;AAAA,IACpE;AAAA,EACG,WAAUf;AAOT,IAAIQ,MACFR,EAAU,QAAQA,EAAU,MAAM,QAAQ,QAAQ,EAAE,IAElDS,MACFA,EAAQ,QAAQA,EAAQ,MAAM,QAAQ,QAAQ,EAAE;AAAA,WAGzCD,KAAaC,GAAS;AAC/B,QAAIO,IAAYP,EAAQ,MAAM,MAAM,MAAM,EAAE,CAAC,GAC3CQ,IAAahB,EAAS,MAAM,MAAM,MAAM,EAAE,CAAC,GAC3CiB,IAAWjB,EAAS,MAAM,MAAM,MAAM,EAAE,CAAC,GAIvCkB,IAAatD,EAAoBmD,GAAWC,CAAU;AAC1D,IAAAhB,EAAS,QAAQzB,EAAayB,EAAS,OAAOkB,CAAU;AAKxD,QAAIC,IAAWpD,EAAoBQ,EAAawC,GAAWG,CAAU,GAAGD,CAAQ;AAChF,IAAAjB,EAAS,QAAQxB,EAAawB,EAAS,OAAOmB,CAAQ,GACtDX,EAAQ,QAAQxC,EAAcwC,EAAQ,OAAOO,GAAWI,CAAQ,GAIhEZ,EAAU,QAAQnC,EAAcmC,EAAU,OAAOQ,GAAWA,EAAU,MAAM,GAAGA,EAAU,SAASI,EAAS,MAAM,CAAC;AAAA,EACnH,WAAUX,GAAS;AAIlB,QAAIY,IAAkBZ,EAAQ,MAAM,MAAM,MAAM,EAAE,CAAC,GAC/Ca,IAAmBrB,EAAS,MAAM,MAAM,MAAM,EAAE,CAAC,GACjDsB,IAAU7C,EAAe4C,GAAkBD,CAAe;AAC9D,IAAApB,EAAS,QAAQxB,EAAawB,EAAS,OAAOsB,CAAO;AAAA,EACtD,WAAUf,GAAW;AAIpB,QAAIgB,IAAoBhB,EAAU,MAAM,MAAM,MAAM,EAAE,CAAC,GACnDiB,IAAmBxB,EAAS,MAAM,MAAM,MAAM,EAAE,CAAC,GACjDyB,IAAWhD,EAAe8C,GAAmBC,CAAgB;AACjE,IAAAxB,EAAS,QAAQzB,EAAayB,EAAS,OAAOyB,CAAQ;AAAA,EAC1D;AACA;AACA,IAAIC,IAAoB,IAAIlH,EAAM;AAClCkH,EAAkB,WAAW,SAAU1G,GAAO;AAM5C,MAAI2G,IAAQ,IAAI,OAAO,cAAc,OAAOvC,GAAmB,qBAAqB,EAAE,OAAOA,GAAmB,GAAG,GAAG,IAAI;AAC1H,SAAOpE,EAAM,MAAM2G,CAAK,KAAK,CAAE;AACjC;AACA,SAASrB,EAAmBF,GAAQC,GAAQzF,GAAS;AACnD,SAAO8G,EAAkB,KAAKtB,GAAQC,GAAQzF,CAAO;AACvD;AAgBA,IAAIgH,IAAW,IAAIpH,EAAM;AACzBoH,EAAS,WAAW,SAAU5G,GAAOJ,GAAS;AAC5C,EAAIA,EAAQ,oBAEVI,IAAQA,EAAM,QAAQ,SAAS;AAAA,CAAI;AAErC,MAAI6G,IAAW,CAAE,GACfC,IAAmB9G,EAAM,MAAM,WAAW;AAG5C,EAAK8G,EAAiBA,EAAiB,SAAS,CAAC,KAC/CA,EAAiB,IAAK;AAIxB,WAAS9E,IAAI,GAAGA,IAAI8E,EAAiB,QAAQ9E,KAAK;AAChD,QAAI+E,IAAOD,EAAiB9E,CAAC;AAC7B,IAAIA,IAAI,KAAK,CAACpC,EAAQ,iBACpBiH,EAASA,EAAS,SAAS,CAAC,KAAKE,IAEjCF,EAAS,KAAKE,CAAI;AAAA,EAExB;AACE,SAAOF;AACT;AACAD,EAAS,SAAS,SAAU/E,GAAMC,GAAOlC,GAAS;AAQhD,SAAIA,EAAQ,qBACN,CAACA,EAAQ,kBAAkB,CAACiC,EAAK,SAAS;AAAA,CAAI,OAChDA,IAAOA,EAAK,KAAM,KAEhB,CAACjC,EAAQ,kBAAkB,CAACkC,EAAM,SAAS;AAAA,CAAI,OACjDA,IAAQA,EAAM,KAAM,MAEblC,EAAQ,sBAAsB,CAACA,EAAQ,mBAC5CiC,EAAK,SAAS;AAAA,CAAI,MACpBA,IAAOA,EAAK,MAAM,GAAG,EAAE,IAErBC,EAAM,SAAS;AAAA,CAAI,MACrBA,IAAQA,EAAM,MAAM,GAAG,EAAE,KAGtBtC,EAAK,UAAU,OAAO,KAAK,MAAMqC,GAAMC,GAAOlC,CAAO;AAC9D;AAkBA,IAAIoH,IAAe,IAAIxH,EAAM;AAC7BwH,EAAa,WAAW,SAAUhH,GAAO;AACvC,SAAOA,EAAM,MAAM,uBAAuB;AAC5C;AAKA,IAAIiH,IAAU,IAAIzH,EAAM;AACxByH,EAAQ,WAAW,SAAUjH,GAAO;AAClC,SAAOA,EAAM,MAAM,eAAe;AACpC;AAwCA,SAASkH,EAAQC,GAAG;AAClB;AAEA,SAAOD,IAAwB,OAAO,UAArB,cAA2C,OAAO,OAAO,YAA1B,WAAqC,SAAUC,GAAG;AAChG,WAAO,OAAOA;AAAA,EACf,IAAG,SAAUA,GAAG;AACf,WAAOA,KAAmB,OAAO,UAArB,cAA+BA,EAAE,gBAAgB,UAAUA,MAAM,OAAO,YAAY,WAAW,OAAOA;AAAA,EACtH,GAAKD,EAAQC,CAAC;AACd;AAyCA,IAAIC,IAAW,IAAI5H,EAAM;AAGzB4H,EAAS,kBAAkB;AAC3BA,EAAS,WAAWR,EAAS;AAC7BQ,EAAS,YAAY,SAAUpH,GAAOJ,GAAS;AAC7C,MAAIyH,IAAuBzH,EAAQ,sBACjC0H,IAAwB1H,EAAQ,mBAChC2H,IAAoBD,MAA0B,SAAS,SAAUpD,GAAGsD,GAAG;AACrE,WAAO,OAAOA,IAAM,MAAcH,IAAuBG;AAAA,EAC/D,IAAQF;AACN,SAAO,OAAOtH,KAAU,WAAWA,IAAQ,KAAK,UAAUyH,EAAazH,GAAO,MAAM,MAAMuH,CAAiB,GAAGA,GAAmB,IAAI;AACvI;AACAH,EAAS,SAAS,SAAUvF,GAAMC,GAAOlC,GAAS;AAChD,SAAOJ,EAAK,UAAU,OAAO,KAAK4H,GAAUvF,EAAK,QAAQ,cAAc,IAAI,GAAGC,EAAM,QAAQ,cAAc,IAAI,GAAGlC,CAAO;AAC1H;AAOA,SAAS6H,EAAaC,GAAKC,GAAOC,GAAkBC,GAAUC,GAAK;AACjE,EAAAH,IAAQA,KAAS,CAAE,GACnBC,IAAmBA,KAAoB,CAAE,GACrCC,MACFH,IAAMG,EAASC,GAAKJ,CAAG;AAEzB,MAAI1F;AACJ,OAAKA,IAAI,GAAGA,IAAI2F,EAAM,QAAQ3F,KAAK;AACjC,QAAI2F,EAAM3F,CAAC,MAAM0F;AACf,aAAOE,EAAiB5F,CAAC;AAG7B,MAAI+F;AACJ,MAAyB,OAAO,UAAU,SAAS,KAAKL,CAAG,MAAvD,kBAA0D;AAI5D,SAHAC,EAAM,KAAKD,CAAG,GACdK,IAAmB,IAAI,MAAML,EAAI,MAAM,GACvCE,EAAiB,KAAKG,CAAgB,GACjC/F,IAAI,GAAGA,IAAI0F,EAAI,QAAQ1F,KAAK;AAC/B,MAAA+F,EAAiB/F,CAAC,IAAIyF,EAAaC,EAAI1F,CAAC,GAAG2F,GAAOC,GAAkBC,GAAUC,CAAG;AAEnF,WAAAH,EAAM,IAAK,GACXC,EAAiB,IAAK,GACfG;AAAA,EACX;AAIE,MAHIL,KAAOA,EAAI,WACbA,IAAMA,EAAI,OAAQ,IAEhBR,EAAQQ,CAAG,MAAM,YAAYA,MAAQ,MAAM;AAC7C,IAAAC,EAAM,KAAKD,CAAG,GACdK,IAAmB,CAAE,GACrBH,EAAiB,KAAKG,CAAgB;AACtC,QAAIC,IAAa,CAAE,GACjBC;AACF,SAAKA,KAAQP;AAEX,MAAI,OAAO,UAAU,eAAe,KAAKA,GAAKO,CAAI,KAChDD,EAAW,KAAKC,CAAI;AAIxB,SADAD,EAAW,KAAM,GACZhG,IAAI,GAAGA,IAAIgG,EAAW,QAAQhG,KAAK;AACtC,MAAAiG,IAAOD,EAAWhG,CAAC,GACnB+F,EAAiBE,CAAI,IAAIR,EAAaC,EAAIO,CAAI,GAAGN,GAAOC,GAAkBC,GAAUI,CAAI;AAE1F,IAAAN,EAAM,IAAK,GACXC,EAAiB,IAAK;AAAA,EAC1B;AACI,IAAAG,IAAmBL;AAErB,SAAOK;AACT;AAEA,IAAIG,IAAY,IAAI1I,EAAM;AAC1B0I,EAAU,WAAW,SAAUlI,GAAO;AACpC,SAAOA,EAAM,MAAO;AACtB;AACAkI,EAAU,OAAOA,EAAU,cAAc,SAAUlI,GAAO;AACxD,SAAOA;AACT;","x_google_ignoreList":[0]}